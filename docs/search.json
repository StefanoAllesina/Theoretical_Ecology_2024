[
  {
    "objectID": "ch3.html",
    "href": "ch3.html",
    "title": "Models for many populations",
    "section": "",
    "text": "Models for many populations"
  },
  {
    "objectID": "ch4.html",
    "href": "ch4.html",
    "title": "Disease models",
    "section": "",
    "text": "Disease models"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "These lecture notes were prepared by Stefano Allesina (sallesina@uchicago.edu) for the graduate class ECEV 42900, Theoretical Ecology, taught at the University of Chicago in Winter Quarter 2024. The notes grew a set of notes from Sarah Cobey.\n\nResources\nThese are good introductions to theoretical ecology:\n\nCase, An Illustrated Guide to Theoretical Ecology, 1999\nMay and McLean, Theoretical Ecology: Principles and Applications, 2007\nGotelli, A primer of ecology, 2008\nHofbauer and Sigmund Evolutionary Games and Population Dynamics, 1998\n\nBooks on disease dynamics:\n\nAnderson and May Infectious Diseases of Humans: Dynamics and Control, 1992\nKeeling and Rohani Modelling Infectious Diseases, 2008\n\n\n\nCourse policies\nThe ethos of the course is collaborative rather than competitive. The instructors are happy to help with assignments and clarifications. Email Stefano Allesina sallesina@uchicago.edu or Greg Dwyer gdwyer@uchicago.edu to meet.\nStudents are expected to work in accordance with the University Policy of Academic Integrity, which can be found here.\nStudents can collaborate, but graded homework should be completed by each student, and not copied from others or from online resources. Students ca use online resources (e.g. StackOverflow, ChatGPT, or other LLMs) to help with coding, but should explicitly acknowledge sources whenever this is the case.\nLate homework: TODO\n\n\nMathematical background\nFollowing the material requires basic notions in calculus, linear algebra and dynamical systems. Here are a few essential concepts that students should be familiar with.\n\nFunctions, exponential function, logarithm\nLimits\nDerivatives and chain rule\nIntegration of functions in one and several variables\nTaylor series\nVectors, dot product, cross product\nMatrix product, transpose, determinant, eigenvalue decomposition\nPositive and negative definiteness of a matrix\n\nThese are good websites offering a brief review of these materials, and cheat sheets reporting the main formulas:\n\nPaul’s Online Notes covering calculus I, II and III as well as dynamical systems; the cheat sheets are excellent.\nSteve Brunton’s (U. Washington) YouTube channel has extremely well-done lectures on dynamical systems; for example, here are reviews of derivatives, Taylor series, simulating the logistic map, integrating ODEs in a computer.\nZiko Kolter has published a brief review of linear algebra concepts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lecture notes, Part 1: Population Dynamics",
    "section": "",
    "text": "The class is divided in two parts. The first part of the class deals with models for population dynamics. We are going to explore:\n\nModels for a single population\nModels for two populations\nModels for many populations\nModels for disease dynamics\n\n\n\nThe GitHub associated with the lecture notes contains the code to generate the lectures and all the figures and simulations. Crucially, these depend on the following R packages:\n\nlibrary(tidyverse) # plotting, data organization\nlibrary(deSolve) # integrate differential equations\n\n\n\n\n\nWe write \\(x(t)\\) for the density of population \\(x\\) at time \\(t\\). In many cases, we will write simply \\(x\\), as the dependency on time is always assumed. For discrete-time models, we write \\(x_t\\) instead. Typically, \\(x(t)\\) is measured in either \\([\\text{mass}]/[\\text{area/volume}]\\) or \\([\\text{number of individuals}]/[\\text{area/volume}]\\)\nThe density of a population typically changes in time, and the change is modulated by several parameters. Unless specified, we use Greek letters for scalars, lower-case Latin letters for vectors, and upper-case Latin letters for matrices.\nOther useful notation:\n\n\\(i\\) is the imaginary unit, such that \\(i^2 = -1\\)\n\\(0_n\\) is a vector of zeros of lenght \\(n\\)\n\\(1_n\\) is a vector of ones of lenght \\(n\\)\n\\(I\\) is the identity matrix (i.e., a matrix with \\(1_n\\) on the diagonal, and zeros elsewhere)\n\\(D(a)\\) is a diagonal matrix with vector \\(a\\) on the diagonal\n\\(\\dfrac{d x(t)}{dt}\\) is sometimes written as \\(\\dfrac{d x}{dt}\\) or \\(\\dot{x}\\)"
  },
  {
    "objectID": "index.html#computing",
    "href": "index.html#computing",
    "title": "Lecture notes, Part 1: Population Dynamics",
    "section": "",
    "text": "The GitHub associated with the lecture notes contains the code to generate the lectures and all the figures and simulations. Crucially, these depend on the following R packages:\n\nlibrary(tidyverse) # plotting, data organization\nlibrary(deSolve) # integrate differential equations"
  },
  {
    "objectID": "index.html#notation",
    "href": "index.html#notation",
    "title": "Lecture notes, Part 1: Population Dynamics",
    "section": "",
    "text": "We write \\(x(t)\\) for the density of population \\(x\\) at time \\(t\\). In many cases, we will write simply \\(x\\), as the dependency on time is always assumed. For discrete-time models, we write \\(x_t\\) instead. Typically, \\(x(t)\\) is measured in either \\([\\text{mass}]/[\\text{area/volume}]\\) or \\([\\text{number of individuals}]/[\\text{area/volume}]\\)\nThe density of a population typically changes in time, and the change is modulated by several parameters. Unless specified, we use Greek letters for scalars, lower-case Latin letters for vectors, and upper-case Latin letters for matrices.\nOther useful notation:\n\n\\(i\\) is the imaginary unit, such that \\(i^2 = -1\\)\n\\(0_n\\) is a vector of zeros of lenght \\(n\\)\n\\(1_n\\) is a vector of ones of lenght \\(n\\)\n\\(I\\) is the identity matrix (i.e., a matrix with \\(1_n\\) on the diagonal, and zeros elsewhere)\n\\(D(a)\\) is a diagonal matrix with vector \\(a\\) on the diagonal\n\\(\\dfrac{d x(t)}{dt}\\) is sometimes written as \\(\\dfrac{d x}{dt}\\) or \\(\\dot{x}\\)"
  },
  {
    "objectID": "ch1.html",
    "href": "ch1.html",
    "title": "Models for a single population",
    "section": "",
    "text": "Consider a population reproducing annually, with non-overlapping generations. Over its lifetime, each individual produces \\(\\rho\\) offspring, which form the next generation. Then, we can write:\n\\[\nx_{k+1} = \\rho x_k\n\\]\nwhere \\(x_k\\) is the number of individuals/area at generation \\(k\\). Naturally, we can iterate again, and find the population density at time \\(x_{k+2}\\):\n\\[\nx_{k+2} = \\rho x_{k+1} = \\rho^2 x_{k}\n\\]\nand in general:\n\\[\nx_{n} = \\rho^n x_0\n\\]\nwhere \\(x_0\\) is the initial population size, and \\(n\\) is the number of generations since we started tracking the population. We assume \\(x_0&gt;0\\), and thus the population grows whenever \\(\\rho &gt; 1\\), declines whenever \\(\\rho &lt; 1\\), and is constant whenever \\(\\rho = 1\\). Armed with \\(x_0\\) and \\(\\rho\\) we can project the population forward in time for an arbitrary number of generations.\n\n\n\nTake the population density at time \\(t\\) and \\(t + \\Delta t\\); in the time interval \\(\\Delta t\\) the change in population density is \\(x(t + \\Delta t) - x(t)\\), and the average change per unit of time is \\((x(t + \\Delta t) - x(t))/\\Delta t\\). We can consider the limit in which the interval \\(\\Delta t\\) shrinks to zero:\n\\[\n\\lim_{\\Delta t \\to 0} \\dfrac{x(t + \\Delta t) - x(t)}{\\Delta t} = \\frac{dx(t)}{dt}\n\\]\nIn fact, this is exactly the definition of the derivative with respect to (w.r.t.) time of the function \\(x(t)\\). A great contribution of Newton and Leibniz was to recognize that many natural phenomena can be described by simple differential equations—even though the equations describing the rate of change \\(dx(t)/dt\\) are simple, the behavior of the solutions \\(x(t)\\) can be incredibly complex.\nIn ecology and evolutionary biology, one encounters two main types of differential equations:\n\nOrdinary differential equations (ODEs) describe the rate of change of a quantity (in our case, population densities, \\(x(t)\\)) as a function of an independent variable (in our case, the time \\(t\\)), and can contain functions of the quantity, and its derivatives. If only the first derivative (\\(dx(t)/dt\\)) is included, it is called a first-order ODE.\nPartial differential equations (PDEs) contain more than one independent variable (e.g., time and coordinates in space). Therefore, the quantity of interest is a multivariate function, such as \\(q(x,y,t)\\), denoting the density of a population at the coordinates \\(x,y\\) and time \\(t\\). The partial derivatives with respect to the independent variables are considered, hence the name.\n\nMany other types of differential equations (stochastic differential equations, SDEs; integro-differential equations, IDEs; etc.) are found in certain technical areas.\nIn this class, we will deal exclusively with ODEs of the form:\n\\[\n\\dfrac{dx(t)}{dt} = f(x(t))\n\\]\nwhere the function \\(f(x(t))\\) models different ecological phenomena influencing the growth and decline of populations. For example, take populations growing thanks to the per-capita birth rate \\(\\beta\\), and declining due to the death rate \\(\\delta\\):\n\\[\n\\dfrac{dx(t)}{dt} = \\beta x(t) - \\delta x(t) = (\\beta - \\delta) x(t) = \\rho\\, x(t)\n\\]\nhere the intrinsic growth rate \\(\\rho\\) represents the difference between birth and death rates. The parameter is taken to be independent of time, yielding an autonomous differential equation. An ODE is autonomous if it does not depend explicitly on the independent variable (in our case, time). I.e., if \\(dx/dt = f(x(t))\\) the system is autonomous, while \\(dx/dt = g(x(t),t)\\) is not.\n\n\n\n\n\n\nSeparation of variables\n\n\n\n\n\nA differential equation for \\(x(t)\\) is called separable, if it can be written as:\n\\[\n\\frac{dx(t)}{dt} = g(t)\\, h(x(t))\n\\]\nwhere \\(g(t)\\) is a function of \\(t\\), and \\(h(x(t))\\) a function of \\(x(t)\\). As long as \\(h(x(t)) \\neq 0\\), we can formally write:\n\\[\n\\frac{1}{h(x(t))} dx(t) = g(t)\\, dt\n\\]\nWe can now integrate both sides, obtaining\n\\[\n\\begin{aligned}\n\\int \\frac{1}{h(x(t))} dx(t) + \\mathcal c_1 &= \\int g(t)\\, dt + \\mathcal c_2\\\\\n\\int \\frac{1}{h(x(t))} dx(t) &= \\int g(t)\\, dt + \\mathcal c\n\\end{aligned}\n\\]\nwhere \\(\\mathcal c_1, \\mathcal c_2\\) and \\(\\mathcal c = \\mathcal c_2 - \\mathcal c_1\\) are constants of integration, whose value can be set by considering the initial conditions.\nExample\nConsider:\n\\[\n\\frac{dx(t)}{dt} = \\alpha\n\\]\nwith initial condition \\(x(0) = x_0\\). Separate the variables and integrate:\n\\[\n\\begin{aligned}\nd x(t) &= \\alpha\\, dt\\\\\n\\int d x(t) &= \\alpha \\int dt + \\mathcal c\\\\\nx(t) &= \\alpha t + \\mathcal c\n\\end{aligned}\n\\]\nNow substitute the initial condition:\n\\[\nx(0) = x_0 = \\alpha 0 + c  = c\n\\]\nYielding the solution:\n\\[\nx(t) = x_0 + \\alpha t\n\\]\nA solution of an initial-value problem is an equation which, given the values of the parameters (\\(\\alpha\\), in this case) and the initial conditions (\\(x_0\\), in this case), allows us to determine the value of the dependent variable (\\(x(t)\\)) for any value of the independent variable (\\(t\\)). Only relatively simple ODEs or systems of ODEs can be solved explicitly.\n\n\n\nWe can solve the differential equation:\n\\[\n\\begin{aligned}\n\\dfrac{dx}{dt} &= \\rho\\, x\\\\\n\\dfrac{1}{x}\\,dx &= \\rho\\, dt\n\\end{aligned}\n\\]\nIntegrate both sides\n\\[\n\\begin{aligned}\n\\int \\dfrac{1}{x}\\,dx &= \\int \\rho\\, dt\\\\\n\\log x &= \\rho\\, t + \\mathcal c\\\\\nx &= e^{\\rho\\, t  + \\mathcal c}\\\\\nx &= e^{\\rho\\, t} e^\\mathcal c\\\\\n\\end{aligned}\n\\]\nwhere \\(\\mathcal c\\) is a constant of integration. Then, we can plug in the initial condition: at \\(t=0\\), the population is at density \\(x_0\\):\n\\[\n\\begin{aligned}\nx_0 &= e^{\\rho\\, 0}e^{\\mathcal c}\\\\\nx_0 &= e^\\mathcal c\n\\end{aligned}\n\\]\nWe obtain the solution:\n\\[\nx(t) = x(0) e^{\\rho\\, t}\n\\]\n\n\n\n\n\n\nIntegrating differential equations numerically\n\n\n\n\n\nYou can compute \\(x(t)\\) for any differential equation (or system of differential equations) in R using numerical techniques. Your code needs to include two parts:\nFirst, we write a function defining the (system of) ODE(s). This function takes three arguments: t, the time, x, the state of the system, and parms, a list of parameters, and returns a list containing \\(dx/dt\\). For the exponential growth, we can write:\n\nexponential_growth &lt;- function(t, x, parms){\n  dxdt &lt;- x * parms$rho\n  return(list(dxdt))\n}\n\nBecause ecological models only make sense for positive population densities, we can set an arbitrarily small threshold, and consider the population extinct if it falls below the threshold:\n\nTHRESH &lt;- 10^-10\n\nexponential_growth &lt;- function(t, x, parms){\n  if(x &lt; THRESH) x &lt;- 0\n  dxdt &lt;- x * parms$rho\n  return(list(dxdt))\n}\n\nThe second part of the code invokes the numerical integration function ode. For this function, we need to set a) initial conditions, b) determine at which times do we want to observe the state of the population, c) specify the name of the function to use, d) the parameters to use, and e) (optional) specify the method to use for the integration. The function ode is part of the package deSolve:\n\nx0 &lt;- 1 # initial conditions\nmy_time &lt;- seq(0, 5, by = 0.1) # we will observe the system at these times\nparms &lt;- list(rho = 1.05) # list of parameters\noutput &lt;- ode(y = x0, # a) initial conditions\n             times = my_time,  # b) time at which we observe the system\n             func = exponential_growth, # c) function computing r.h.s. of ODEs\n             parms = parms, # d) parameters of ODEs\n             method = \"ode45\") # e) more on this later; this is a good general-purpose choice\n\nThe output is a matrix of class deSolve, containing the time in the first column, and the values of \\(x(t)\\) in the second. For plotting, it is best to convert this into a data frame:\n\noutput %&gt;% \n  as.data.frame() %&gt;% \n  ggplot() + aes(x = time, y = `1`) + \n  geom_point() + \n  geom_line() + \n  xlab(\"t\") + \n  ylab(expression(x(t))) + \n  theme_bw()\n\n\n\n\n\n\n\n\n\nHow long will it take for a growing population (\\(\\rho &gt; 0\\)) to double in density? We are looking for \\(\\tau\\) such that \\[\n\\begin{aligned}\nx(\\tau) &= 2 x_0\\\\\nx_0 e^{\\rho \\tau} &= 2 x_0\\\\\ne^{\\rho \\tau} &= 2\\\\\n\\rho \\tau &= \\log 2\\\\\n\\tau &= \\dfrac{\\log 2}{\\rho}\n\\end{aligned}\n\\]\nThus, the doubling time does not depend on the initial condition: the population will keep doubling every \\(\\log 2 / \\rho\\) units of time. For example, take \\(\\rho = 0.01\\), then \\(\\tau \\approx 30\\): a population growing exponentially with rate of 1% per year will double every 30 years or so. Then, a growth of 3% doubles every 10 years, etc.\n\n\n\n\n\n\nExercise: Radiocarbon dating\n\n\n\n\n\nWhile at the University of Chicago, Willard Libby (Nobel Laureate in Chemistry, 1960) pioneered radiocarbon dating. The carbon isotope \\({}^{14}\\)C is constantly being created in the Earth’s atmosphere by the interaction of cosmic rays with atmospheric nitrogen. The carbon combines with oxygen, to form CO\\({}_2\\) that is then absorbed by plants. When plants die, the isotope decays in their tissues. Radioactive decay follows the exponential model:\n\\[\nN(t) = e^{\\lambda t} N(0)\n\\]\nwhere \\(\\lambda &lt; 0\\) is the decay rate of the isotope. The half-life of a radioisotope is the time it takes to be reduced to half of the original concentration, and is 5,730 years for \\({}^{14}\\)C.\n\nFind the value of \\(\\lambda\\) for \\({}^{14}\\)C given its half-life\nExpress \\(t\\) as a function of \\(\\lambda\\), and the ratio between \\(N(t)\\) and \\(N(0)\\)\nThe concentration in the atmosphere is about 1 atom of \\({}^{14}\\)C for every \\(10^{12}\\) atoms of carbon. You have a collected sample that contains \\(1/16\\) atoms of \\({}^{14}\\)C for every \\(10^{12}\\) atoms of carbon; date the sample.\n\n\n\n\n\n\n\n\nWe have a population that grows exponentially when at very low densities, but experiences a slow down in growth when densities are higher. The logistic growth equation is typically written as:\n\\[\n\\frac{d X}{d \\tau} = X\\left(\\rho - \\alpha X\\right)\n\\]\nwhere \\(\\rho&gt;0\\) is the intrinsic growth rate of the population, and \\(\\alpha&gt;0\\) is a parameter that regulates the amount by which growth is decreased as \\(X\\) increases.\nAn equilibrium (steady-state, fixed point) of a differential equation is a value of the dependent variable (\\(X(t)\\)) that makes the right-hand side of the equation zero. We denote an equilibrium as \\(X^\\star\\). We can write:\n\\[\n\\left.\\dfrac{dX}{d\\tau}\\right|_{X^\\star} = 0\n\\]\ni.e., the differential equation, evaluated at the point \\(X^\\star\\) is zero: the population will not grow nor decline, but rather will remain at \\(X^\\star\\). The logistic equation has two equilibria: \\(X^\\star=0\\) (absence of the population), and \\(\\rho = \\alpha X^\\star\\), \\(X^\\star = \\rho / \\alpha = \\kappa\\), called the carrying capacity of the population.\n\n\n\n\n\n\nChain rule\n\n\n\n\n\nThis is one of the most useful formulas from calculus. It relates the derivative of the composition of two differentiable functions with the derivatives of the functions. If \\(h(x) = g(u)\\) and \\(u = f(x)\\), then:\n\\[\n\\dfrac{dh}{dx} = \\dfrac{dg}{du}\\dfrac{du}{dx}\n\\]\nAs put by George Simmons [Calculus with Analytic Geometry (1985)]: If a car travels twice as fast as a bicycle and the bicycle is four times as fast as a walking man, then the car travels 2 × 4 = 8 times as fast as the man.\nExample\nTake\n\\[\n\\dfrac{dx(t)}{dt} = x(t) f(x(t))\n\\]\nand write the ODE describing \\(d \\log x(t) /dt\\). We can write this function as the derivative of the composition \\(\\log x(t) = \\log u\\) and \\(u = x(t)\\). Then, by chain rule:\n\\[\n\\begin{aligned}\n\\dfrac{d \\log x(t)}{dt} &= \\dfrac{d \\log u}{du} \\dfrac{du}{dt}\\\\\n&= \\dfrac{1}{u} \\dfrac{du}{dt}\\\\\n&= \\dfrac{1}{x(t)} \\dfrac{d x(t)}{dt}\\\\\n&= \\dfrac{1}{x(t)}  x(t) f(x(t))\\\\\n&= f(x(t))\n\\end{aligned}\n\\]\nshowing that the per-capita rate of change:\n\\[\n\\dfrac{1}{x(t)} \\dfrac{dx(t)}{dt} = \\dfrac{\\log x(t)}{dt}\n\\]\nis the derivative in time of the logarithm of the density of the population.\n\n\n\nWe can simplify the analysis of the differential equation by rescaling all the variables by positive quantities, thus obtaining a simpler form that retains the behavior of the original equation.\n\n\n\n\n\n\nNondimensionalization\n\n\n\n\n\nEcological models can have many parameters, and the goal of nondimensionalization is to rewrite the equations using as few parameters as possible, via a change of variables. Importantly, the new system and the original one are equivalent, and share the same dynamics. In fact, the trajectories of the original system can be reconstructed from those of the simpler system by inverting the transformation.\nTo perform nondimensionalization:\n\nidentify all the variables that depend on time (\\(X(\\tau)\\), \\(Y(\\tau)\\), etc.), as well as the independent variable (the time, \\(\\tau\\))\nreplace each of them by a scaled version: \\(X = c_x x\\), \\(Y = c_y y\\), \\(t = c_t \\tau\\), in which \\(c_i\\) are positive constants to be determined, and rewrite the equations for the new variables\nchoose the values for the constants to eliminate as many parameters as possible. Generally, one should be able to remove one parameter for each dependent variable, plus one parameter by scaling the time.\n\nExample\nThe exponential growth equation has a single parameter:\n\\[\n\\frac{dx}{d\\tau} = \\rho x\n\\]\none can define \\(t = c_1 \\tau\\), obtaining:\n\\[\n\\begin{aligned}\n\\frac{1}{c_1}\\frac{dx}{dt} &= \\rho x\\\\\n\\frac{dx}{dt} &= c_1 \\rho x\\\\\n\\frac{dx}{dt} &= x\n\\end{aligned}\n\\]\nwhere we have chosen \\(c_1 = 1/\\rho\\).\n\n\n\nWe rewrite the equation for the logistic growth by choosing \\(x = c_1 X\\) and \\(t = c_2 \\tau\\). Our equations become (use the chain rule):\n\\[\n\\begin{aligned}\n\\dfrac{c_1}{c_2}\\dfrac{dx}{dt} &= c_1 x (\\rho - \\alpha c_1 x)\\\\\n\\dfrac{dx}{dt} &= x (\\rho c_2 - \\alpha c_1 c_2 x)\\\\\n\\end{aligned}\n\\]\nWe choose \\(c_2 = 1/\\rho\\) to make the first coefficient in parenthesis be equal to 1; then, we choose \\(c_1 = \\rho/\\alpha\\) to make the second coefficient be 1:\n\\[\n\\dfrac{dx}{dt} = x (1 - x)\n\\]\nNote that, in practice, we have chosen to rescale the variables using the intrinsic growth rate, \\(t = \\tau / \\rho\\), and the carrying capacity, \\(x = X \\alpha / \\rho = X / \\kappa\\).\nThe logistic equation can be solved, because it is separable:\n\\[\n\\begin{aligned}\n\\dfrac{1}{x(1-x)} dx &= dt\\\\\n\\left(\\dfrac{1}{x}-\\dfrac{1}{x-1}\\right)dx &= dt\\\\\n\\int \\dfrac{1}{x} dx - \\int \\dfrac{1}{1-x} dx &= \\int dt + \\mathcal c\\\\\n\\log x - \\log(x-1)&= t + c\\\\\n\\log \\dfrac{x}{x-1}&= t + c\\\\\n\\dfrac{x}{x-1} &= e^t e^c\\\\\nx &= \\dfrac{e^t e^c}{e^t e^c - 1}\\\\\nx &= \\dfrac{1}{1 - e^{-t}e^{-c}}\n\\end{aligned}\n\\]\nPlugging in \\(x_0\\) when \\(t=0\\), we find the value for the constant of proportionality:\n\\[\n\\begin{aligned}\nx_0 &= \\frac{e^c}{e^c - 1}\\\\\ne^c &= \\frac{x_0}{x_0 - 1}\n\\end{aligned}\n\\]\nYielding the solution\n\\[\nx(t) = \\dfrac{x_0 e^t}{1 + (e^t - 1)x_0}\n\\]\n\n\n\nAs shown for the logistic growth, solving ODEs can be very hard, and for most equations found in ecology a closed-form solution cannot be found. Moreover, even when we can solve the equations, the solution might be difficult to interpret or overly complex. Important information on the behavior of the system can be found by performing a qualitative analysis of the system. Here we concentrate on the location of equilibria, and their stability.\n\n\nFor any first-order ODE with a single dependent variable, one can understand the behavior of the system by simply plotting \\(dx(t)/dt\\) (y-axis) vs \\(x(t)\\) (x-axis). For example, for the logistic model:\n\\[\n\\dfrac{dx}{dt} = x(1-x)\n\\]\n\n\n\n\n\nShowing that there are two equilibria (\\(x^\\star =0\\), and \\(x^\\star = 1\\)), corresponding to the points where the curve \\(dx/dt\\) intercepts the x-axis. The function \\(dx/dt\\) is positive whenever \\(0&lt;x&lt;1\\), and is negative when \\(x&gt;1\\). Thus, the population will grow in time when \\(0&lt;x&lt;1\\), eventually reaching \\(x^\\star = 1\\); similarly, if we start the population at a density that is larger than the equilibrium, it will decline, again eventually reaching \\(x^\\star = 1\\). We therefore say that \\(x^\\star = 1\\) is asymptotically stable.\n\n\n\n\n\n\nAsymptotic stability\n\n\n\n\n\nThere are two useful notions of equilibrium stability for dynamical systems. We state them informally; you can find a more rigorous definition in any book on dynamical systems.\nLyapunov stability For a given dynamical system \\(dx(t)/dt\\), \\(x^\\star\\) is Lyapunov stable if trajectories starting close to \\(x^\\star\\) remain close to it, indefinitely. More formally, we define a neighborhood of \\(x^\\star\\), \\(\\| x(0) - x^\\star\\| &lt; \\delta\\); then \\(x^\\star\\) is Lyapunov stable if \\(\\| x(t) - x^\\star\\| &lt; \\epsilon\\) for every \\(t\\), where \\(\\epsilon &gt; 0\\).\nAsymptotic stability An equilibrium is asymptotically stable if it is Lyapunov stable, and trajectories eventually converge to \\(x^\\star\\): \\(x^\\star\\) is asymptotically stable if there exist a neighborhood \\(\\| x(0) - x^\\star\\| &lt; \\delta\\) such that \\(\\lim_{t\\to\\infty}\\| x(t) - x^\\star\\| = 0\\).\n\n\n\nThe logistic model assumes that the per capita growth rate is higher at low densities. This assumption may not be realistic for all species: when the density is low, for example, it can be more difficult to find a partner and defend against predators. This phenomenon of lower per capita growth rates at low densities, and higher per capita growth at high densities—which can also be called positive density-dependence—is known as the Allee effect. It is named after Warder Clyde Allee (1885-1955), who received his PhD from the University of Chicago and was later a professor and chair of Zoology. We could model this effect with the following equation:\n\\[\n\\dfrac{dX}{dt} = X\\left(\\dfrac{u X}{v + X} - c X \\right) = X^2 \\left(\\dfrac{u}{v + X} - c  \\right)\n\\]\nwhere \\(c\\) is the density-dependent death rate. Assume that all parameters are positive; then, besides the trivial equilibrium \\(X^\\star =0\\), we have a positive equilibrium \\(X^\\star = \\frac{u}{c} - v &gt; 0\\).\n\n\n\n\n\nThe graphical method allows to classify all equilibria according to their stability in a straightforward manner. Here’s an example with many equilibria:\n\n\n\n\n\n\n\n\n\n\n\nExercise: Strong Allee effect\n\n\n\n\n\nA stronger version of the Allee effect can be modeled as:\n\\[\n\\dfrac{dX}{dt} = X (X - \\gamma)(\\kappa - X)\n\\]\nwith \\(0&lt;\\gamma &lt; \\kappa\\).\n\nInterpret the parameters\nPlot \\(dX/dt\\) vs \\(X\\), and identify all equilibria\nClassify the equilibria according to their stability\n\n\n\n\n\n\n\n\nYou might have noticed that, when performing the graphical analysis above, and equilibrium is stable if \\(dx/dt\\) has a negative slope at \\(x^\\star\\). Here we formalize this notion, by considering small perturbations of the system resting at an equilibrium.\n\nTake an ODE \\(dx/dt = f(x)\\)\nThe system is resting at an equilibrium \\(x^\\star\\)\nWe perturb the system, and track the dynamics when starting at \\(x(0) = x^\\star + \\epsilon\\), where \\(\\epsilon\\) (the perturbation) is taken to be sufficiently small \\(\\| \\epsilon \\| \\ll 1\\)\nWe write \\(\\Delta x(0) = x(0) - x^\\star\\)\nWe derive the dynamics for \\(\\Delta x\\):\n\nBy chain rule,\n\\[\n\\begin{aligned}\n\\dfrac{d \\Delta x}{dt} &= \\dfrac{d \\Delta x}{dx} \\dfrac{d x}{dt} \\\\\n&= 1 \\dfrac{d x}{dt}\\\\\n&= f(x)\\\\\n&= f(\\Delta x + x^\\star)\n\\end{aligned}\n\\] Where we have substituted \\(x = \\Delta x + x^\\star\\).\n\nNow we approximate the function \\(f(\\Delta x + x^\\star)\\) by Talyor expanding.\n\n\n\n\n\n\n\nTaylor series\n\n\n\n\n\nWe can approximate the behavior of a (infinitely differentiable) function in the vicinity of a point \\(a\\) by a power series:\n\\[\nf(x) = f(a) + \\dfrac{1}{1!} \\left. \\dfrac{df(x)}{dx} \\right|_a (x-a)+ \\dfrac{1}{2!} \\left. \\dfrac{d^2f(x)}{dx^2} \\right|_a (x-a)^2+ \\dfrac{1}{3!} \\left. \\dfrac{d^3f(x)}{dx^3} \\right|_a (x-a)^3 + \\ldots\n\\] where \\(n! = n (n-1)(n-2)\\ldots 1\\) is the factorial function and the derivatives are evaluated at \\(a\\). When we choose \\(a=0\\) this is called the Maclaurin series.\nExample\nExpand \\(e^x\\) around \\(0\\):\n\\[\n\\begin{aligned}\ne^x &= e^0 + \\left. e^x\\right|_0 x + \\frac{1}{2}\\left. e^x\\right|_0 x^2  + \\frac{1}{6}\\left. e^x\\right|_0 x^3 + \\ldots\\\\\n&=1 + x + \\frac{1}{2} x^2  + \\frac{1}{6}x^3 + \\ldots\\\\\n&=\\sum_{k=0}^\\infty \\frac{x^k}{k!}\n\\end{aligned}\n\\]\n\n\n\nWe want to Taylor-expand \\(f(x) = f(\\Delta x + x^\\star)\\) around \\(x^\\star\\):\n\\[\nf(x) = f(x^\\star) + \\left.\\dfrac{d f(x)}{d x}\\right|_{x^\\star} (x - x^\\star) + \\dfrac{1}{2}\\left.\\dfrac{d^2 f(x)}{d x^2}\\right|_{x^\\star} (x - x^\\star)^2 + \\ldots\n\\] Note that \\(f(x^\\star) = 0\\) by the definition of an equilibrium. If the deviation is small, we can neglect all the higher-order terms, obtaining:\n\\[\n\\dfrac{d \\Delta x}{dt} = f(x) \\approx \\left.\\dfrac{d f(x)}{d x}\\right|_{x^\\star} \\Delta x\n\\]\nwhich is the equation of the exponential growth model, with \\(\\rho = \\left.\\dfrac{d f(x)}{d x}\\right|_{x^\\star}\\). Then, the solution is \\(\\Delta x(t) = \\Delta x(0) e^{\\rho t}\\), and the deviation from the equilibrium goes to zero (i.e., the system goes back to \\(x^\\star\\)) whenever \\(\\rho &lt; 0\\).\nFor example, take the logistic growth model and evaluate the stability of \\(x^\\star = 1\\); we have:\n\\[\n\\left.\\dfrac{d f(x)}{d x}\\right|_{x^\\star} = \\left.\\dfrac{d (x - x^2)}{d x}\\right|_{x^\\star} = \\left.(1 - 2x)\\right|_{x^\\star} = -1\n\\]\nand thus the equilibrium is locally asymptotically stable. Locally, because we have considered very small deviations from the equilibrium, and asymptotic because convergence only happens eventually.\n\n\n\n\n\n\nExercise: Stability of equilibria for strong Allee effect\n\n\n\n\n\nTake the function for the Allee effect in the previous exercise:\n\\[\n\\dfrac{dX}{dt} = X (X - \\gamma)(\\kappa - X)\n\\]\nUse local stability analysis to show that the system has three equilibria, of which two are locally stable.\n\n\n\n\n\n\n\n\n\nExercise: Stability of model with weak Allee effect\n\n\n\n\n\nNow analyze the stability of the model with weak Allee effects:\n\\[\n\\dfrac{dX}{dt} = X^2 \\left(\\dfrac{u}{v + X} - c  \\right)\n\\]\nAssuming that \\(u/c &gt; v\\). You will find that the analysis of the equilibrium \\(X^\\star = 0\\) is inconclusive; expand the function \\(d\\Delta X/dt\\) to include higher-order terms to determine the stability of the equilibrium.\n\n\n\n\n\n\n\n\n\nExercise: Levins’ metapopulation model\n\n\n\n\n\nIn 1969, when he was a professor at the University of Chicago, Richard Levins proposed a model for metapopulation dynamics. The idea is that in a landscape there are numerous patches of suitable habitat that can be colonized by a given species. Each population in a patch undergoes extinction with a certain rate, and can colonize other patches by sending propagules to them. Because there are many patches, we track the proportion of occupied patches \\(0 \\leq p(t) \\leq 1\\); the proportion of empty patches is therefore \\(1 - p(t)\\). If individuals disperse to a random patch when leaving an occupied patch, the rate of colonization will be proportional to the product \\(\\gamma\\, p(t)(1-p(t))\\) (i.e., \\(\\gamma\\, p(t)\\) is the rate at which propagules are produced, and \\(1-p(t)\\) is the rate at which they land on an empty patch). The rate at which patches are vacated, the extinction rate, is \\(\\delta\\). The model can be written as:\n\\[\n\\dfrac{d p(t)}{dt} = \\gamma\\,p(t)(1 - p(t)) - \\delta\\, p(t)\n\\]\n\nFind the equilibria\nDetermine their stability\nShow that the equation is equivalent to that for the logitstic growth\n\n\n\n\n\n\n\nIn certain models, we can show that whenever the population starts at a positive value, it will always reach a certain equilibrium \\(x^\\star\\). In this case, we say the equilibrium is globally asymptotically stable.\nBecause as we said solving differential equations is in general very difficult, and in many cases of interest impossible, we employ a proxy function, called a Lyapunov function.\n\n\n\n\n\n\nLyapunov functions\n\n\n\n\n\nWe want to prove that all trajectories originating at \\(x(0) &gt; 0\\) eventually converge to \\(x^\\star\\). If we can find a function \\(V\\) such that:\n\n\\(V(x(t)) \\geq 0\\) for all \\(x(t) &gt; 0\\)\n\\(V(x(t)) = 0\\) if and only if \\(x(t) = x^\\star\\)\n\\(\\dfrac{d V(x(t))}{dt} \\leq 0\\) for all \\(t\\) and\n\\(\\dfrac{d V(x(t))}{dt} = 0\\) if and only if \\(x(t) = x^\\star\\)\n\nthen \\(x^\\star\\) is globally asymptotically stable: all trajectories starting at a positive point will converge to it.\nThe logic of this procedure is to identify a suitable function \\(V\\) that is positive everywhere but at the equilibrium, and is constantly declining in time; then necessarily the function will eventually reach zero, which is attained only at equilibrium.\nExample\n\\(V(x(t)) = (x(t) - x^\\star)^2\\) is a Lyapunov function that can be used to prove that the logistic growth model \\(dx/dt = x(1-x)\\) has an equilibrium \\(x^\\star = 1\\) that is globally asymptotically stable.\n\n\\(V(x(t))\\) is always nonnegative, and is zero only at \\(x(t) = x^\\star = 1\\)\nThe derivative of \\(V(x(t))\\) w.r.t. time is:\n\n\\[\n\\begin{aligned}\n\\dfrac{dV(t)}{dt} &= \\dfrac{dV(t)}{dx(t)}\\dfrac{dx(t)}{dt}\\\\\n&= 2(x(t) - x^\\star)\\dfrac{dx(t)}{dt}\\\\\n&=2(x(t)-1) x(t)(x(t)-1)\\\\\n&=2 x(t) (x(t)-1)^2 \\geq 0\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nExercise: Global stability of logistic growth\n\n\n\n\n\nShow that \\(V(x(t)) = x(t) - 1 - \\log x(t)\\) is a Lyapunov function that can be used to prove the global stability of \\(x^\\star = 1\\) for the logistic growth model \\(dx/dt = x(1-x)\\).\n\nProve that \\(V \\geq 0\\), with equality only at equilibrium\nProve that \\(dV/dt \\leq 0\\), with equality only at equilibrium\n\n\n\n\n\n\nAutonomous, first-order ODE models with a single variable can have only two types of behavior: a) \\(x(t)\\) eventually reaches a fixed point and remains there; b) \\(x(t)\\) goes to \\(\\pm \\infty\\). This is a consequence of an important mathematical fact: if \\(dx(t)/dt = f(x(t))\\) and the function \\(f(x(t))\\) is “smooth” (e.g., continuously differentiable) then the solution for the ODE exists and is unique. This means that the equation can cross each point \\(x(t) = \\alpha\\) only once, or infinitely many times. In contrast, discrete models with a single variable can have very interesting behavior.\n\n\n\n\nWe have so far analyzed models where the growth of a population is described by an ordinary differential equation. However, for particular situations, and especially for species with nonoverlapping generations, a discrete-time approach would be more suitable.\n\n\nTo understand whether a discrete model is stable, we analyze the plot of \\(x_{t+1}\\) against \\(x_t\\), superimposed on the diagonal (\\(x_{t+1}=x_{t}\\)). We use these two curves to “cobweb”:\n\nStarting from an initial condition \\(x_t=x(0)\\) (some point on the x-axis), we draw a line to the model’s projection of the population at the next time step (\\(x_{t+1}\\))\nWe then set \\(x_t=x_{t+1}\\) to obtain the population in the next time step. To speed the process along, rather than lifting our pencils to draw \\(x_{t+1}\\) at \\(x_t\\) on the x-axis, we can simply draw a horizontal line from \\(x_{t+1}\\) back to the diagonal (which shows \\(x_{t+1}=x_t\\)) and then move vertically to get the next \\(x_{t+1}\\)\nWith enough iterations, this process reveals whether the population converges to a fixed point or does something more elaborate, and if this trajectory involves oscillations. Note that at a fixed point, \\(x_{t+1}=x_t=x^\\star\\).\n\nWe can use this approach for any map (discrete-time model) of \\(x_{t+1}\\) to \\(x_t\\), although cobwebbing suffers the disadvantage of requiring a lot of manual labor to explore the asymptotic behavior. To explore its uses further, we’ll consider one of the most basic and important density-dependent, discrete-time models: the logistic map.\n\n\n\nThis is a model with a very similar formulation to the logistic growth ODE above:\n\\[\nx_{t+1} = r\\, x_t (1 - x_t)\n\\]\nWith \\(x_t &gt; 0\\) and \\(r &gt; 0\\). When \\(x_t &gt; 1\\), the population will decline; therefore it makes sense to start the population at a value \\(0&lt;x_0&lt;1\\). For these values, the population might grow only if \\(r &gt; 1\\) (i.e., we want \\(x_{t+1} &gt; x_t\\) for growth).\nLet’s try our hand at cobwebbing: set \\(x_0 = 1/2\\) and \\(r = 3/2\\). The cobwebbing plot becomes:\n\n\n\n\n\nshowing that the population declines and then stops at an equilibrium. We can compute the equilibrium by setting \\(x_{t+1} = x_t = x^\\star\\):\n\\[\n\\begin{aligned}\nx^\\star &= r\\, x^\\star (1 - x^\\star)\\\\\n1 &= r\\, (1 - x^\\star)\\\\\nx^\\star &= 1 - \\frac{1}{r}\n\\end{aligned}\n\\]\nThus, a feasible (positive) equilibrium is found only for \\(r &gt; 1\\), as expected. In the example above, the equilibrium is reached without oscillations. Let’s try the cobweb for a larger \\(r = 5/2\\)\n\n\n\n\n\nNow the solution \\(x^\\star = 1 - \\frac{2}{5} = \\frac{3}{5}\\) is reached after oscillating above and below this value.\n\n\n\nWe want to determine whether \\(x^\\star\\) is stable for a given map (discrete-time model) \\(x_{t+1} = f(x_t)\\), with \\(f(x^\\star)=x^\\star\\). In particular, we want to determine whether when we initialize the system close to \\(x^\\star\\) we converge back to \\(x^\\star\\).\nTake \\(x_t = x^\\star + \\epsilon_t\\), where \\(\\epsilon_t\\) is small. Then we have\n\\[\n\\begin{aligned}\nx_{t+1} &= f(x_t)\\\\\nx^\\star + \\epsilon_{t+1} &= f(x^\\star + \\epsilon_t)\\\\\nx^\\star + \\epsilon_{t+1} &\\approx f(x^\\star) + \\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star} (x_t - x^\\star) \\\\\nx^\\star + \\epsilon_{t+1} &\\approx x^\\star + \\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star} \\epsilon_t\\\\\n\\epsilon_{t+1} &\\approx \\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star} \\epsilon_t\\\\\n\\end{aligned}\n\\]\nwhich is the very first model we have written. We have:\n\\[\n\\epsilon_{t+k} = \\rho^{k} \\epsilon_t\n\\]\nwith \\(\\rho = \\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star}\\). We have that\n\\[\n\\lim_{k \\to \\infty} \\epsilon_{t+k} = 0 \\quad \\text{if} \\, |\\rho| &lt; 1\n\\]\nThus, the equilibrium is stable if and only if the absolute value of \\(\\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star}\\) is less than 1. If this value is greater than 1, then the equilibrium is unstable: small perturbations will amplify (at least initially); if the value is exactly 1, the analysis is inconclusive, and we might want to consider including higher-order terms in the Taylor expansion above.\nExample\nTake \\(r = 2\\), and show that the equilibrium \\(x^\\star = 1/2\\) is stable. We take the derivative:\n\\[\n\\rho = \\left.\\dfrac{d f(x_t)}{d x_t} \\right|_{x^\\star} = r \\left. \\dfrac{d (x_t (1- x_t))}{d x_t}\\right|_{x^\\star} = \\left. r (1 - 2 x_t)\\right|_{x^\\star}\n\\]\nand substitute the values of \\(r\\) and \\(x_t = x^\\star = 1/2\\). We obtain \\(\\rho = 0\\) and thus the equilibrium is stable. In fact, we see that, for any value of \\(r &gt; 0\\) leading to a feasible equilibrium, we have:\n\\[\n\\rho = r \\left(1 - 2 \\left(1 - \\frac{1}{r} \\right) \\right) = 2 - r\n\\]\nand thus whenever \\(|2 - r| &lt; 1\\) we have a stable equilibrium. This is true whenever \\(3&gt; r &gt;1\\).\n\n\n\nIf we make \\(r\\) even larger, we find new behavior. For example, take \\(r = 10/3\\), \\(x_0 = 3/4\\)\n\n\n\n\n\nAfter a few oscillations, the system sets into a cycle, alternating between two values. This is best seen by plotting a time-series, in which we have the (discrete) time in the x-axis, and the value \\(x_t\\) on the y-axis:\n\n\n\n\n\nWhat are the two values? To find them, we can set \\(x_{t+2} = x_{t}\\) making sure that \\(x_{t+1} \\neq x_t\\). Take:\n\\[\n\\begin{aligned}\nx_{t+2} &= x_t\\\\\nf(x_{t+1}) &= x_t\\\\\nf(f(x_t)) &= x_t\\\\\nf^{(2)}(x_t) &= x_t\n\\end{aligned}\n\\]\nFor the logistic map, we have:\n\\[\n\\begin{aligned}\nx_t &= r\\,x_{t+1}\\,(1 - x_{t+1})\\\\\n&= r\\, r\\, x_t (1 - x_t)\\, (1 -  r\\, x_t (1 - x_t))\\\\\n&= r^2 x_t (1-x_t) (1 -  r\\, x_t (1 - x_t))\n\\end{aligned}\n\\]\nWhen we discard the solution \\(x_t =0\\), we obtain the cubic polynomial:\n\\[\n-r^3 x_t^3+2 r^3 x_t^2-(r+1) r^2 x_t+r^2-1= 0\n\\]\nWe can factor out the solution \\(x_t = 1 - \\frac{1}{r}\\), which we know already, obtaining:\n\\[\n\\begin{aligned}\nr^3 x_t^2 - r^2 (1 + r) x_t + r (1 + r) &= 0\\\\\nr^2 x_t^2 - r (1 + r) x_t + (1 + r) &= 0\n\\end{aligned}\n\\]\nYielding:\n\\[\nx_c = \\dfrac{r +1 \\pm \\sqrt{(r-3) (r+1)}}{2 r}\n\\]\nBoth values are greater than zero whenever \\(r \\geq 3\\). We can investigate the stability of the cycle, we can take the derivative w.r.t. \\(x_t\\) of \\(f^{(2)}(x_t)\\), and plug in one of the two values above:\n\\[\n\\begin{aligned}\n\\rho &= \\left.\\dfrac{d f^{(2)}(x_t)}{d x_t} \\right|_{x_c}\\\\\n&= \\left. \\left(\\dfrac{d}{d x_t} r^2 x_t (1-x_t) (1 -  r\\, x_t (1 - x_t)) \\right)\\right|_{x_c}\\\\\n&= \\left. (r^2 (1 - 2 x_t)(1 - 2 r x_t(1-x_t))) \\right|_{x_c}\n\\end{aligned}\n\\]\nSubstituting the larger value of \\(x_c\\), we eventually find:\n\\[\n\\rho = 4 - r (r - 2)\n\\]\nThe period-2 cycle is stable whenever \\(|\\rho| &lt; 1\\). If we assume that \\(r \\geq 3\\) (required for the existence of the cycle in the first place), we have:\n\\[\n3 &lt; \\rho &lt; 1 + \\sqrt{6} \\approx 3.45\n\\]\nThe period-2 orbits are therefore stable in this range. What happens beyond this value of \\(r\\)? Take \\(r = 3.5\\) and cobweb:\n\n\n\n\n\nNow we have that the system oscillates between four values, as seen from the time-series (where we have removed the first 250 time steps for clarity):\n\n\n\n\n\nNow we have a period-4 solution, which is stable until \\(1 + \\sqrt{6} &lt; r &lt; 3.701\\), at which point we find period-8 cycles:\n\n\n\n\n\n\n\n\nThe system can yield cycles of period three. Take \\(r = 1 + 2 \\sqrt{2}\\), and plot the time series:\n\n\n\n\n\nA famous result (Sharkovsky’s theorem, Ukrainian Math J, 1964) states that if a map has cycles of period 3, then it must have cycles of every other period. Li and Yorke (“Period Three Implies Chaos”. Am. Math. Monthly, 1975) showed that indeed a period-three implies infinitely many trajectories that do not have a period, and oscillate without ever completing a cycle. We call this phenomenon chaos.\nChaos is aperiodic long-term behavior in a deterministic system that exhibits sensitive dependence to initial conditions. In particular, one can prove that in a chaotic regime, if we start with two initial conditions that are very close to each other (their distance being \\(\\Delta x_0\\)) we eventually find very different trajectories. In particular, when we have chaos:\n\\[\n|\\Delta x(t)| \\approx e^{\\lambda t}|\\Delta x_0|\n\\]\nwith \\(\\lambda&gt;0\\) (the Lyapunov exponent).\nTo show this behavior, let’s plot two trajectories for the system when \\(r = 3.675\\) and \\(x_0 = 0.5\\) or \\(x_0 = 0.4999\\):\n\n\n\n\n\n\n\n\nAll these results can be summarized in a beautiful graph. We build it as follows:\n\npick a value of \\(r\\)\nstarting from an arbitrary point, \\(x_0 = 1/2\\), compute \\(x_t\\) for a large number of points, and discard the first part of the time series (transient dynamics)\nlocate and record the minima and maxima of the time series\nplot \\(r\\) (x-axis) against the location of the minima and maxima (y-axis)\n\nIf the trajectories converge to an equilibrium, we will find a single point; if trajectories converge to a period-2 cycle, we will find two points; etc.\n\nlogistic_map_ts &lt;- function(r, max_time = 3000, discard = 2000){\n  ts &lt;- accumulate(.x = rep(1/2, max_time), .f = function(xt, xtp1) r * xt * (1-xt))[discard:max_time]\n  # discard points at which the trajectory repeats\n  difference &lt;- abs(ts - ts[1])\n  zz &lt;- which(difference &lt; 10^-6)\n  if(length(zz) &gt; 1) ts &lt;- ts[1:zz[2]]\n  return(tibble('x' = ts, 'r' = r))\n}\n# load results if available\nif (file.exists(\"data/logistic_bifurcation.RData\")){\n  load(\"data/logistic_bifurcation.RData\")\n} else {\n  # compute the results (this will take some time...)\n  bifurcation_logistic_map &lt;- map_df(.x = seq(2.95, 3.99, by = 0.001), \n                                     .f = logistic_map_ts)  \n  # and save the file\n  save(bifurcation_logistic_map, file = \"data/logistic_bifurcation.RData\")\n}\nggplot(bifurcation_logistic_map) + \n  aes(x = r, y = x) + \n  geom_point(size = 0.005, alpha = 0.2) + \n  theme_bw() + \n  xlab(expression(r)) + ylab(expression(x[t]))\n\n\n\n\n\n\n\n\n\n\nExercise: Ricker model\n\n\n\n\n\nThis period-doubling cascade to chaos is common to several models. Draw the bifurcation diagram for the Ricker model:\n\\[\nx_{t+1} = x_t e^{r(1-x_t)}\n\\]\nagain taking values of \\(r\\) between 1.95 and 4, and values of \\(x_0\\) between 0 and 1.\n\n\n\n\n\n\n\n\n\nEuler’s method\n\n\n\n\n\nWhen we want to compute trajectories for a differential equations, we face the problem that typically the equations cannot be solved. Computers get around this issue by carefully computing the trajectory for a discrete-time model. The simplest case is that of Euler’s method.\nWe want to compute the solution of \\(dx(t)/dt = f(x(t))\\). For sufficiently small \\(\\Delta t\\), we can Taylor-expand \\(x(t_0 + \\Delta t)\\) around \\(t_0\\), obtaining:\n\\[\nx(t_0 + \\Delta t) \\approx x(t_0) + \\left. \\dfrac{d x(t)}{dt}\\right|_{t_0} \\Delta t\n\\]\nwe know the value of \\(x(t_0) = x_0\\), and the function \\(d x(t) / dt = f(x(t))\\), and as such:\n\\[\nx(t_0 + \\Delta t) \\approx x_0 + \\Delta t \\, f(x_0)\n\\]\nWe iterate this procedure again and again, drawing our trajectory. Naturally, taking smaller \\(\\Delta t\\) we should get better approximations, from a mathematical standpoint. In fact, one can show that the error we’re making is proportional to \\(\\Delta t\\). However, reducing \\(\\Delta t\\) has two undesirable effects: first, the calculation time will increase accordingly; second, because computers have limited precision when representing numbers, at each step we will make round off errors, and these will accumulate faster when the step size is small.\nIn practice, when we use Euler’s method we assume that \\(f(x)\\) is fixed during the step \\(\\Delta t\\) (which we now is generally not true). We can average across two points, yielding the so-called midpoint method:\n\\[\n\\begin{aligned}\ny_{t + \\Delta t} &= x_t + \\Delta_t f(x_t)\\\\\nx_{t + \\Delta t} &= x_t + \\frac{1}{2}(f(x_t) + f(y_{t + \\Delta t}))\n\\end{aligned}\n\\]\nwhere \\(y_{t + \\Delta t}\\) is what computed using Euler’s method, and the slope for the actual step is taken to be the average \\(f(x)\\) at the beginning and end of the step. One can show that the error is now proportional to \\((\\Delta t)^2\\), which is a good improvement.\nThe same logic applies when we take several intermediate steps, and average across them, as done for the Runge-Kutta methods.\nIn fact, the best software tries to pick small \\(\\Delta t\\) when \\(x(t)\\) is changing rapidly, and larger \\(\\Delta t\\) when \\(x(t)\\) is changing slowly. These adaptive-step methods are the state-of-the-art, and are implemented in the package deSolve in R.\n\n\n\n\n\n\n\nA brief paper discussing how to build models in biology:\n\nRichard Levins, 1966. The strategy of model building in population biology. American Scientist 54:421-431\n\nThis paper introduces the famous metapopulation model:\n\nRichard Levins, 1969. Some demographic and genetic consequences of environmental heterogeneity for biological control. Bull. Entomol. Soc. Am. 15:237–240.\n\nThis paper shows the onset of chaos in simple discrete-time models:\n\nRobert M. May, 1976. Simple mathematical models with very complicated dynamics. Nature 261:459-467\n\nThis paper discusses how simple models relates to experimental data on population growth:\n\nMichael P. Hassell, John H. Lawton, Robert M. May, 1976. Patterns of dynamical behavior in single species populations. Journal of Animal Ecology 45:471-486"
  },
  {
    "objectID": "ch1.html#a-simple-model-for-non-overlapping-generations",
    "href": "ch1.html#a-simple-model-for-non-overlapping-generations",
    "title": "Models for a single population",
    "section": "",
    "text": "Consider a population reproducing annually, with non-overlapping generations. Over its lifetime, each individual produces \\(\\rho\\) offspring, which form the next generation. Then, we can write:\n\\[\nx_{k+1} = \\rho x_k\n\\]\nwhere \\(x_k\\) is the number of individuals/area at generation \\(k\\). Naturally, we can iterate again, and find the population density at time \\(x_{k+2}\\):\n\\[\nx_{k+2} = \\rho x_{k+1} = \\rho^2 x_{k}\n\\]\nand in general:\n\\[\nx_{n} = \\rho^n x_0\n\\]\nwhere \\(x_0\\) is the initial population size, and \\(n\\) is the number of generations since we started tracking the population. We assume \\(x_0&gt;0\\), and thus the population grows whenever \\(\\rho &gt; 1\\), declines whenever \\(\\rho &lt; 1\\), and is constant whenever \\(\\rho = 1\\). Armed with \\(x_0\\) and \\(\\rho\\) we can project the population forward in time for an arbitrary number of generations."
  },
  {
    "objectID": "ch1.html#overlapping-generations-exponential-growth",
    "href": "ch1.html#overlapping-generations-exponential-growth",
    "title": "Models for a single population",
    "section": "",
    "text": "Take the population density at time \\(t\\) and \\(t + \\Delta t\\); in the time interval \\(\\Delta t\\) the change in population density is \\(x(t + \\Delta t) - x(t)\\), and the average change per unit of time is \\((x(t + \\Delta t) - x(t))/\\Delta t\\). We can consider the limit in which the interval \\(\\Delta t\\) shrinks to zero:\n\\[\n\\lim_{\\Delta t \\to 0} \\dfrac{x(t + \\Delta t) - x(t)}{\\Delta t} = \\frac{dx(t)}{dt}\n\\]\nIn fact, this is exactly the definition of the derivative with respect to (w.r.t.) time of the function \\(x(t)\\). A great contribution of Newton and Leibniz was to recognize that many natural phenomena can be described by simple differential equations—even though the equations describing the rate of change \\(dx(t)/dt\\) are simple, the behavior of the solutions \\(x(t)\\) can be incredibly complex.\nIn ecology and evolutionary biology, one encounters two main types of differential equations:\n\nOrdinary differential equations (ODEs) describe the rate of change of a quantity (in our case, population densities, \\(x(t)\\)) as a function of an independent variable (in our case, the time \\(t\\)), and can contain functions of the quantity, and its derivatives. If only the first derivative (\\(dx(t)/dt\\)) is included, it is called a first-order ODE.\nPartial differential equations (PDEs) contain more than one independent variable (e.g., time and coordinates in space). Therefore, the quantity of interest is a multivariate function, such as \\(q(x,y,t)\\), denoting the density of a population at the coordinates \\(x,y\\) and time \\(t\\). The partial derivatives with respect to the independent variables are considered, hence the name.\n\nMany other types of differential equations (stochastic differential equations, SDEs; integro-differential equations, IDEs; etc.) are found in certain technical areas.\nIn this class, we will deal exclusively with ODEs of the form:\n\\[\n\\dfrac{dx(t)}{dt} = f(x(t))\n\\]\nwhere the function \\(f(x(t))\\) models different ecological phenomena influencing the growth and decline of populations. For example, take populations growing thanks to the per-capita birth rate \\(\\beta\\), and declining due to the death rate \\(\\delta\\):\n\\[\n\\dfrac{dx(t)}{dt} = \\beta x(t) - \\delta x(t) = (\\beta - \\delta) x(t) = \\rho\\, x(t)\n\\]\nhere the intrinsic growth rate \\(\\rho\\) represents the difference between birth and death rates. The parameter is taken to be independent of time, yielding an autonomous differential equation. An ODE is autonomous if it does not depend explicitly on the independent variable (in our case, time). I.e., if \\(dx/dt = f(x(t))\\) the system is autonomous, while \\(dx/dt = g(x(t),t)\\) is not.\n\n\n\n\n\n\nSeparation of variables\n\n\n\n\n\nA differential equation for \\(x(t)\\) is called separable, if it can be written as:\n\\[\n\\frac{dx(t)}{dt} = g(t)\\, h(x(t))\n\\]\nwhere \\(g(t)\\) is a function of \\(t\\), and \\(h(x(t))\\) a function of \\(x(t)\\). As long as \\(h(x(t)) \\neq 0\\), we can formally write:\n\\[\n\\frac{1}{h(x(t))} dx(t) = g(t)\\, dt\n\\]\nWe can now integrate both sides, obtaining\n\\[\n\\begin{aligned}\n\\int \\frac{1}{h(x(t))} dx(t) + \\mathcal c_1 &= \\int g(t)\\, dt + \\mathcal c_2\\\\\n\\int \\frac{1}{h(x(t))} dx(t) &= \\int g(t)\\, dt + \\mathcal c\n\\end{aligned}\n\\]\nwhere \\(\\mathcal c_1, \\mathcal c_2\\) and \\(\\mathcal c = \\mathcal c_2 - \\mathcal c_1\\) are constants of integration, whose value can be set by considering the initial conditions.\nExample\nConsider:\n\\[\n\\frac{dx(t)}{dt} = \\alpha\n\\]\nwith initial condition \\(x(0) = x_0\\). Separate the variables and integrate:\n\\[\n\\begin{aligned}\nd x(t) &= \\alpha\\, dt\\\\\n\\int d x(t) &= \\alpha \\int dt + \\mathcal c\\\\\nx(t) &= \\alpha t + \\mathcal c\n\\end{aligned}\n\\]\nNow substitute the initial condition:\n\\[\nx(0) = x_0 = \\alpha 0 + c  = c\n\\]\nYielding the solution:\n\\[\nx(t) = x_0 + \\alpha t\n\\]\nA solution of an initial-value problem is an equation which, given the values of the parameters (\\(\\alpha\\), in this case) and the initial conditions (\\(x_0\\), in this case), allows us to determine the value of the dependent variable (\\(x(t)\\)) for any value of the independent variable (\\(t\\)). Only relatively simple ODEs or systems of ODEs can be solved explicitly.\n\n\n\nWe can solve the differential equation:\n\\[\n\\begin{aligned}\n\\dfrac{dx}{dt} &= \\rho\\, x\\\\\n\\dfrac{1}{x}\\,dx &= \\rho\\, dt\n\\end{aligned}\n\\]\nIntegrate both sides\n\\[\n\\begin{aligned}\n\\int \\dfrac{1}{x}\\,dx &= \\int \\rho\\, dt\\\\\n\\log x &= \\rho\\, t + \\mathcal c\\\\\nx &= e^{\\rho\\, t  + \\mathcal c}\\\\\nx &= e^{\\rho\\, t} e^\\mathcal c\\\\\n\\end{aligned}\n\\]\nwhere \\(\\mathcal c\\) is a constant of integration. Then, we can plug in the initial condition: at \\(t=0\\), the population is at density \\(x_0\\):\n\\[\n\\begin{aligned}\nx_0 &= e^{\\rho\\, 0}e^{\\mathcal c}\\\\\nx_0 &= e^\\mathcal c\n\\end{aligned}\n\\]\nWe obtain the solution:\n\\[\nx(t) = x(0) e^{\\rho\\, t}\n\\]\n\n\n\n\n\n\nIntegrating differential equations numerically\n\n\n\n\n\nYou can compute \\(x(t)\\) for any differential equation (or system of differential equations) in R using numerical techniques. Your code needs to include two parts:\nFirst, we write a function defining the (system of) ODE(s). This function takes three arguments: t, the time, x, the state of the system, and parms, a list of parameters, and returns a list containing \\(dx/dt\\). For the exponential growth, we can write:\n\nexponential_growth &lt;- function(t, x, parms){\n  dxdt &lt;- x * parms$rho\n  return(list(dxdt))\n}\n\nBecause ecological models only make sense for positive population densities, we can set an arbitrarily small threshold, and consider the population extinct if it falls below the threshold:\n\nTHRESH &lt;- 10^-10\n\nexponential_growth &lt;- function(t, x, parms){\n  if(x &lt; THRESH) x &lt;- 0\n  dxdt &lt;- x * parms$rho\n  return(list(dxdt))\n}\n\nThe second part of the code invokes the numerical integration function ode. For this function, we need to set a) initial conditions, b) determine at which times do we want to observe the state of the population, c) specify the name of the function to use, d) the parameters to use, and e) (optional) specify the method to use for the integration. The function ode is part of the package deSolve:\n\nx0 &lt;- 1 # initial conditions\nmy_time &lt;- seq(0, 5, by = 0.1) # we will observe the system at these times\nparms &lt;- list(rho = 1.05) # list of parameters\noutput &lt;- ode(y = x0, # a) initial conditions\n             times = my_time,  # b) time at which we observe the system\n             func = exponential_growth, # c) function computing r.h.s. of ODEs\n             parms = parms, # d) parameters of ODEs\n             method = \"ode45\") # e) more on this later; this is a good general-purpose choice\n\nThe output is a matrix of class deSolve, containing the time in the first column, and the values of \\(x(t)\\) in the second. For plotting, it is best to convert this into a data frame:\n\noutput %&gt;% \n  as.data.frame() %&gt;% \n  ggplot() + aes(x = time, y = `1`) + \n  geom_point() + \n  geom_line() + \n  xlab(\"t\") + \n  ylab(expression(x(t))) + \n  theme_bw()\n\n\n\n\n\n\n\n\n\nHow long will it take for a growing population (\\(\\rho &gt; 0\\)) to double in density? We are looking for \\(\\tau\\) such that \\[\n\\begin{aligned}\nx(\\tau) &= 2 x_0\\\\\nx_0 e^{\\rho \\tau} &= 2 x_0\\\\\ne^{\\rho \\tau} &= 2\\\\\n\\rho \\tau &= \\log 2\\\\\n\\tau &= \\dfrac{\\log 2}{\\rho}\n\\end{aligned}\n\\]\nThus, the doubling time does not depend on the initial condition: the population will keep doubling every \\(\\log 2 / \\rho\\) units of time. For example, take \\(\\rho = 0.01\\), then \\(\\tau \\approx 30\\): a population growing exponentially with rate of 1% per year will double every 30 years or so. Then, a growth of 3% doubles every 10 years, etc.\n\n\n\n\n\n\nExercise: Radiocarbon dating\n\n\n\n\n\nWhile at the University of Chicago, Willard Libby (Nobel Laureate in Chemistry, 1960) pioneered radiocarbon dating. The carbon isotope \\({}^{14}\\)C is constantly being created in the Earth’s atmosphere by the interaction of cosmic rays with atmospheric nitrogen. The carbon combines with oxygen, to form CO\\({}_2\\) that is then absorbed by plants. When plants die, the isotope decays in their tissues. Radioactive decay follows the exponential model:\n\\[\nN(t) = e^{\\lambda t} N(0)\n\\]\nwhere \\(\\lambda &lt; 0\\) is the decay rate of the isotope. The half-life of a radioisotope is the time it takes to be reduced to half of the original concentration, and is 5,730 years for \\({}^{14}\\)C.\n\nFind the value of \\(\\lambda\\) for \\({}^{14}\\)C given its half-life\nExpress \\(t\\) as a function of \\(\\lambda\\), and the ratio between \\(N(t)\\) and \\(N(0)\\)\nThe concentration in the atmosphere is about 1 atom of \\({}^{14}\\)C for every \\(10^{12}\\) atoms of carbon. You have a collected sample that contains \\(1/16\\) atoms of \\({}^{14}\\)C for every \\(10^{12}\\) atoms of carbon; date the sample."
  },
  {
    "objectID": "ch1.html#logistic-equation",
    "href": "ch1.html#logistic-equation",
    "title": "Models for a single population",
    "section": "",
    "text": "We have a population that grows exponentially when at very low densities, but experiences a slow down in growth when densities are higher. The logistic growth equation is typically written as:\n\\[\n\\frac{d X}{d \\tau} = X\\left(\\rho - \\alpha X\\right)\n\\]\nwhere \\(\\rho&gt;0\\) is the intrinsic growth rate of the population, and \\(\\alpha&gt;0\\) is a parameter that regulates the amount by which growth is decreased as \\(X\\) increases.\nAn equilibrium (steady-state, fixed point) of a differential equation is a value of the dependent variable (\\(X(t)\\)) that makes the right-hand side of the equation zero. We denote an equilibrium as \\(X^\\star\\). We can write:\n\\[\n\\left.\\dfrac{dX}{d\\tau}\\right|_{X^\\star} = 0\n\\]\ni.e., the differential equation, evaluated at the point \\(X^\\star\\) is zero: the population will not grow nor decline, but rather will remain at \\(X^\\star\\). The logistic equation has two equilibria: \\(X^\\star=0\\) (absence of the population), and \\(\\rho = \\alpha X^\\star\\), \\(X^\\star = \\rho / \\alpha = \\kappa\\), called the carrying capacity of the population.\n\n\n\n\n\n\nChain rule\n\n\n\n\n\nThis is one of the most useful formulas from calculus. It relates the derivative of the composition of two differentiable functions with the derivatives of the functions. If \\(h(x) = g(u)\\) and \\(u = f(x)\\), then:\n\\[\n\\dfrac{dh}{dx} = \\dfrac{dg}{du}\\dfrac{du}{dx}\n\\]\nAs put by George Simmons [Calculus with Analytic Geometry (1985)]: If a car travels twice as fast as a bicycle and the bicycle is four times as fast as a walking man, then the car travels 2 × 4 = 8 times as fast as the man.\nExample\nTake\n\\[\n\\dfrac{dx(t)}{dt} = x(t) f(x(t))\n\\]\nand write the ODE describing \\(d \\log x(t) /dt\\). We can write this function as the derivative of the composition \\(\\log x(t) = \\log u\\) and \\(u = x(t)\\). Then, by chain rule:\n\\[\n\\begin{aligned}\n\\dfrac{d \\log x(t)}{dt} &= \\dfrac{d \\log u}{du} \\dfrac{du}{dt}\\\\\n&= \\dfrac{1}{u} \\dfrac{du}{dt}\\\\\n&= \\dfrac{1}{x(t)} \\dfrac{d x(t)}{dt}\\\\\n&= \\dfrac{1}{x(t)}  x(t) f(x(t))\\\\\n&= f(x(t))\n\\end{aligned}\n\\]\nshowing that the per-capita rate of change:\n\\[\n\\dfrac{1}{x(t)} \\dfrac{dx(t)}{dt} = \\dfrac{\\log x(t)}{dt}\n\\]\nis the derivative in time of the logarithm of the density of the population.\n\n\n\nWe can simplify the analysis of the differential equation by rescaling all the variables by positive quantities, thus obtaining a simpler form that retains the behavior of the original equation.\n\n\n\n\n\n\nNondimensionalization\n\n\n\n\n\nEcological models can have many parameters, and the goal of nondimensionalization is to rewrite the equations using as few parameters as possible, via a change of variables. Importantly, the new system and the original one are equivalent, and share the same dynamics. In fact, the trajectories of the original system can be reconstructed from those of the simpler system by inverting the transformation.\nTo perform nondimensionalization:\n\nidentify all the variables that depend on time (\\(X(\\tau)\\), \\(Y(\\tau)\\), etc.), as well as the independent variable (the time, \\(\\tau\\))\nreplace each of them by a scaled version: \\(X = c_x x\\), \\(Y = c_y y\\), \\(t = c_t \\tau\\), in which \\(c_i\\) are positive constants to be determined, and rewrite the equations for the new variables\nchoose the values for the constants to eliminate as many parameters as possible. Generally, one should be able to remove one parameter for each dependent variable, plus one parameter by scaling the time.\n\nExample\nThe exponential growth equation has a single parameter:\n\\[\n\\frac{dx}{d\\tau} = \\rho x\n\\]\none can define \\(t = c_1 \\tau\\), obtaining:\n\\[\n\\begin{aligned}\n\\frac{1}{c_1}\\frac{dx}{dt} &= \\rho x\\\\\n\\frac{dx}{dt} &= c_1 \\rho x\\\\\n\\frac{dx}{dt} &= x\n\\end{aligned}\n\\]\nwhere we have chosen \\(c_1 = 1/\\rho\\).\n\n\n\nWe rewrite the equation for the logistic growth by choosing \\(x = c_1 X\\) and \\(t = c_2 \\tau\\). Our equations become (use the chain rule):\n\\[\n\\begin{aligned}\n\\dfrac{c_1}{c_2}\\dfrac{dx}{dt} &= c_1 x (\\rho - \\alpha c_1 x)\\\\\n\\dfrac{dx}{dt} &= x (\\rho c_2 - \\alpha c_1 c_2 x)\\\\\n\\end{aligned}\n\\]\nWe choose \\(c_2 = 1/\\rho\\) to make the first coefficient in parenthesis be equal to 1; then, we choose \\(c_1 = \\rho/\\alpha\\) to make the second coefficient be 1:\n\\[\n\\dfrac{dx}{dt} = x (1 - x)\n\\]\nNote that, in practice, we have chosen to rescale the variables using the intrinsic growth rate, \\(t = \\tau / \\rho\\), and the carrying capacity, \\(x = X \\alpha / \\rho = X / \\kappa\\).\nThe logistic equation can be solved, because it is separable:\n\\[\n\\begin{aligned}\n\\dfrac{1}{x(1-x)} dx &= dt\\\\\n\\left(\\dfrac{1}{x}-\\dfrac{1}{x-1}\\right)dx &= dt\\\\\n\\int \\dfrac{1}{x} dx - \\int \\dfrac{1}{1-x} dx &= \\int dt + \\mathcal c\\\\\n\\log x - \\log(x-1)&= t + c\\\\\n\\log \\dfrac{x}{x-1}&= t + c\\\\\n\\dfrac{x}{x-1} &= e^t e^c\\\\\nx &= \\dfrac{e^t e^c}{e^t e^c - 1}\\\\\nx &= \\dfrac{1}{1 - e^{-t}e^{-c}}\n\\end{aligned}\n\\]\nPlugging in \\(x_0\\) when \\(t=0\\), we find the value for the constant of proportionality:\n\\[\n\\begin{aligned}\nx_0 &= \\frac{e^c}{e^c - 1}\\\\\ne^c &= \\frac{x_0}{x_0 - 1}\n\\end{aligned}\n\\]\nYielding the solution\n\\[\nx(t) = \\dfrac{x_0 e^t}{1 + (e^t - 1)x_0}\n\\]"
  },
  {
    "objectID": "ch1.html#qualitative-analysis",
    "href": "ch1.html#qualitative-analysis",
    "title": "Models for a single population",
    "section": "",
    "text": "As shown for the logistic growth, solving ODEs can be very hard, and for most equations found in ecology a closed-form solution cannot be found. Moreover, even when we can solve the equations, the solution might be difficult to interpret or overly complex. Important information on the behavior of the system can be found by performing a qualitative analysis of the system. Here we concentrate on the location of equilibria, and their stability.\n\n\nFor any first-order ODE with a single dependent variable, one can understand the behavior of the system by simply plotting \\(dx(t)/dt\\) (y-axis) vs \\(x(t)\\) (x-axis). For example, for the logistic model:\n\\[\n\\dfrac{dx}{dt} = x(1-x)\n\\]\n\n\n\n\n\nShowing that there are two equilibria (\\(x^\\star =0\\), and \\(x^\\star = 1\\)), corresponding to the points where the curve \\(dx/dt\\) intercepts the x-axis. The function \\(dx/dt\\) is positive whenever \\(0&lt;x&lt;1\\), and is negative when \\(x&gt;1\\). Thus, the population will grow in time when \\(0&lt;x&lt;1\\), eventually reaching \\(x^\\star = 1\\); similarly, if we start the population at a density that is larger than the equilibrium, it will decline, again eventually reaching \\(x^\\star = 1\\). We therefore say that \\(x^\\star = 1\\) is asymptotically stable.\n\n\n\n\n\n\nAsymptotic stability\n\n\n\n\n\nThere are two useful notions of equilibrium stability for dynamical systems. We state them informally; you can find a more rigorous definition in any book on dynamical systems.\nLyapunov stability For a given dynamical system \\(dx(t)/dt\\), \\(x^\\star\\) is Lyapunov stable if trajectories starting close to \\(x^\\star\\) remain close to it, indefinitely. More formally, we define a neighborhood of \\(x^\\star\\), \\(\\| x(0) - x^\\star\\| &lt; \\delta\\); then \\(x^\\star\\) is Lyapunov stable if \\(\\| x(t) - x^\\star\\| &lt; \\epsilon\\) for every \\(t\\), where \\(\\epsilon &gt; 0\\).\nAsymptotic stability An equilibrium is asymptotically stable if it is Lyapunov stable, and trajectories eventually converge to \\(x^\\star\\): \\(x^\\star\\) is asymptotically stable if there exist a neighborhood \\(\\| x(0) - x^\\star\\| &lt; \\delta\\) such that \\(\\lim_{t\\to\\infty}\\| x(t) - x^\\star\\| = 0\\).\n\n\n\nThe logistic model assumes that the per capita growth rate is higher at low densities. This assumption may not be realistic for all species: when the density is low, for example, it can be more difficult to find a partner and defend against predators. This phenomenon of lower per capita growth rates at low densities, and higher per capita growth at high densities—which can also be called positive density-dependence—is known as the Allee effect. It is named after Warder Clyde Allee (1885-1955), who received his PhD from the University of Chicago and was later a professor and chair of Zoology. We could model this effect with the following equation:\n\\[\n\\dfrac{dX}{dt} = X\\left(\\dfrac{u X}{v + X} - c X \\right) = X^2 \\left(\\dfrac{u}{v + X} - c  \\right)\n\\]\nwhere \\(c\\) is the density-dependent death rate. Assume that all parameters are positive; then, besides the trivial equilibrium \\(X^\\star =0\\), we have a positive equilibrium \\(X^\\star = \\frac{u}{c} - v &gt; 0\\).\n\n\n\n\n\nThe graphical method allows to classify all equilibria according to their stability in a straightforward manner. Here’s an example with many equilibria:\n\n\n\n\n\n\n\n\n\n\n\nExercise: Strong Allee effect\n\n\n\n\n\nA stronger version of the Allee effect can be modeled as:\n\\[\n\\dfrac{dX}{dt} = X (X - \\gamma)(\\kappa - X)\n\\]\nwith \\(0&lt;\\gamma &lt; \\kappa\\).\n\nInterpret the parameters\nPlot \\(dX/dt\\) vs \\(X\\), and identify all equilibria\nClassify the equilibria according to their stability"
  },
  {
    "objectID": "ch1.html#local-asymptotic-stability",
    "href": "ch1.html#local-asymptotic-stability",
    "title": "Models for a single population",
    "section": "",
    "text": "You might have noticed that, when performing the graphical analysis above, and equilibrium is stable if \\(dx/dt\\) has a negative slope at \\(x^\\star\\). Here we formalize this notion, by considering small perturbations of the system resting at an equilibrium.\n\nTake an ODE \\(dx/dt = f(x)\\)\nThe system is resting at an equilibrium \\(x^\\star\\)\nWe perturb the system, and track the dynamics when starting at \\(x(0) = x^\\star + \\epsilon\\), where \\(\\epsilon\\) (the perturbation) is taken to be sufficiently small \\(\\| \\epsilon \\| \\ll 1\\)\nWe write \\(\\Delta x(0) = x(0) - x^\\star\\)\nWe derive the dynamics for \\(\\Delta x\\):\n\nBy chain rule,\n\\[\n\\begin{aligned}\n\\dfrac{d \\Delta x}{dt} &= \\dfrac{d \\Delta x}{dx} \\dfrac{d x}{dt} \\\\\n&= 1 \\dfrac{d x}{dt}\\\\\n&= f(x)\\\\\n&= f(\\Delta x + x^\\star)\n\\end{aligned}\n\\] Where we have substituted \\(x = \\Delta x + x^\\star\\).\n\nNow we approximate the function \\(f(\\Delta x + x^\\star)\\) by Talyor expanding.\n\n\n\n\n\n\n\nTaylor series\n\n\n\n\n\nWe can approximate the behavior of a (infinitely differentiable) function in the vicinity of a point \\(a\\) by a power series:\n\\[\nf(x) = f(a) + \\dfrac{1}{1!} \\left. \\dfrac{df(x)}{dx} \\right|_a (x-a)+ \\dfrac{1}{2!} \\left. \\dfrac{d^2f(x)}{dx^2} \\right|_a (x-a)^2+ \\dfrac{1}{3!} \\left. \\dfrac{d^3f(x)}{dx^3} \\right|_a (x-a)^3 + \\ldots\n\\] where \\(n! = n (n-1)(n-2)\\ldots 1\\) is the factorial function and the derivatives are evaluated at \\(a\\). When we choose \\(a=0\\) this is called the Maclaurin series.\nExample\nExpand \\(e^x\\) around \\(0\\):\n\\[\n\\begin{aligned}\ne^x &= e^0 + \\left. e^x\\right|_0 x + \\frac{1}{2}\\left. e^x\\right|_0 x^2  + \\frac{1}{6}\\left. e^x\\right|_0 x^3 + \\ldots\\\\\n&=1 + x + \\frac{1}{2} x^2  + \\frac{1}{6}x^3 + \\ldots\\\\\n&=\\sum_{k=0}^\\infty \\frac{x^k}{k!}\n\\end{aligned}\n\\]\n\n\n\nWe want to Taylor-expand \\(f(x) = f(\\Delta x + x^\\star)\\) around \\(x^\\star\\):\n\\[\nf(x) = f(x^\\star) + \\left.\\dfrac{d f(x)}{d x}\\right|_{x^\\star} (x - x^\\star) + \\dfrac{1}{2}\\left.\\dfrac{d^2 f(x)}{d x^2}\\right|_{x^\\star} (x - x^\\star)^2 + \\ldots\n\\] Note that \\(f(x^\\star) = 0\\) by the definition of an equilibrium. If the deviation is small, we can neglect all the higher-order terms, obtaining:\n\\[\n\\dfrac{d \\Delta x}{dt} = f(x) \\approx \\left.\\dfrac{d f(x)}{d x}\\right|_{x^\\star} \\Delta x\n\\]\nwhich is the equation of the exponential growth model, with \\(\\rho = \\left.\\dfrac{d f(x)}{d x}\\right|_{x^\\star}\\). Then, the solution is \\(\\Delta x(t) = \\Delta x(0) e^{\\rho t}\\), and the deviation from the equilibrium goes to zero (i.e., the system goes back to \\(x^\\star\\)) whenever \\(\\rho &lt; 0\\).\nFor example, take the logistic growth model and evaluate the stability of \\(x^\\star = 1\\); we have:\n\\[\n\\left.\\dfrac{d f(x)}{d x}\\right|_{x^\\star} = \\left.\\dfrac{d (x - x^2)}{d x}\\right|_{x^\\star} = \\left.(1 - 2x)\\right|_{x^\\star} = -1\n\\]\nand thus the equilibrium is locally asymptotically stable. Locally, because we have considered very small deviations from the equilibrium, and asymptotic because convergence only happens eventually.\n\n\n\n\n\n\nExercise: Stability of equilibria for strong Allee effect\n\n\n\n\n\nTake the function for the Allee effect in the previous exercise:\n\\[\n\\dfrac{dX}{dt} = X (X - \\gamma)(\\kappa - X)\n\\]\nUse local stability analysis to show that the system has three equilibria, of which two are locally stable.\n\n\n\n\n\n\n\n\n\nExercise: Stability of model with weak Allee effect\n\n\n\n\n\nNow analyze the stability of the model with weak Allee effects:\n\\[\n\\dfrac{dX}{dt} = X^2 \\left(\\dfrac{u}{v + X} - c  \\right)\n\\]\nAssuming that \\(u/c &gt; v\\). You will find that the analysis of the equilibrium \\(X^\\star = 0\\) is inconclusive; expand the function \\(d\\Delta X/dt\\) to include higher-order terms to determine the stability of the equilibrium.\n\n\n\n\n\n\n\n\n\nExercise: Levins’ metapopulation model\n\n\n\n\n\nIn 1969, when he was a professor at the University of Chicago, Richard Levins proposed a model for metapopulation dynamics. The idea is that in a landscape there are numerous patches of suitable habitat that can be colonized by a given species. Each population in a patch undergoes extinction with a certain rate, and can colonize other patches by sending propagules to them. Because there are many patches, we track the proportion of occupied patches \\(0 \\leq p(t) \\leq 1\\); the proportion of empty patches is therefore \\(1 - p(t)\\). If individuals disperse to a random patch when leaving an occupied patch, the rate of colonization will be proportional to the product \\(\\gamma\\, p(t)(1-p(t))\\) (i.e., \\(\\gamma\\, p(t)\\) is the rate at which propagules are produced, and \\(1-p(t)\\) is the rate at which they land on an empty patch). The rate at which patches are vacated, the extinction rate, is \\(\\delta\\). The model can be written as:\n\\[\n\\dfrac{d p(t)}{dt} = \\gamma\\,p(t)(1 - p(t)) - \\delta\\, p(t)\n\\]\n\nFind the equilibria\nDetermine their stability\nShow that the equation is equivalent to that for the logitstic growth"
  },
  {
    "objectID": "ch1.html#global-asymptotic-stability",
    "href": "ch1.html#global-asymptotic-stability",
    "title": "Models for a single population",
    "section": "",
    "text": "In certain models, we can show that whenever the population starts at a positive value, it will always reach a certain equilibrium \\(x^\\star\\). In this case, we say the equilibrium is globally asymptotically stable.\nBecause as we said solving differential equations is in general very difficult, and in many cases of interest impossible, we employ a proxy function, called a Lyapunov function.\n\n\n\n\n\n\nLyapunov functions\n\n\n\n\n\nWe want to prove that all trajectories originating at \\(x(0) &gt; 0\\) eventually converge to \\(x^\\star\\). If we can find a function \\(V\\) such that:\n\n\\(V(x(t)) \\geq 0\\) for all \\(x(t) &gt; 0\\)\n\\(V(x(t)) = 0\\) if and only if \\(x(t) = x^\\star\\)\n\\(\\dfrac{d V(x(t))}{dt} \\leq 0\\) for all \\(t\\) and\n\\(\\dfrac{d V(x(t))}{dt} = 0\\) if and only if \\(x(t) = x^\\star\\)\n\nthen \\(x^\\star\\) is globally asymptotically stable: all trajectories starting at a positive point will converge to it.\nThe logic of this procedure is to identify a suitable function \\(V\\) that is positive everywhere but at the equilibrium, and is constantly declining in time; then necessarily the function will eventually reach zero, which is attained only at equilibrium.\nExample\n\\(V(x(t)) = (x(t) - x^\\star)^2\\) is a Lyapunov function that can be used to prove that the logistic growth model \\(dx/dt = x(1-x)\\) has an equilibrium \\(x^\\star = 1\\) that is globally asymptotically stable.\n\n\\(V(x(t))\\) is always nonnegative, and is zero only at \\(x(t) = x^\\star = 1\\)\nThe derivative of \\(V(x(t))\\) w.r.t. time is:\n\n\\[\n\\begin{aligned}\n\\dfrac{dV(t)}{dt} &= \\dfrac{dV(t)}{dx(t)}\\dfrac{dx(t)}{dt}\\\\\n&= 2(x(t) - x^\\star)\\dfrac{dx(t)}{dt}\\\\\n&=2(x(t)-1) x(t)(x(t)-1)\\\\\n&=2 x(t) (x(t)-1)^2 \\geq 0\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nExercise: Global stability of logistic growth\n\n\n\n\n\nShow that \\(V(x(t)) = x(t) - 1 - \\log x(t)\\) is a Lyapunov function that can be used to prove the global stability of \\(x^\\star = 1\\) for the logistic growth model \\(dx/dt = x(1-x)\\).\n\nProve that \\(V \\geq 0\\), with equality only at equilibrium\nProve that \\(dV/dt \\leq 0\\), with equality only at equilibrium\n\n\n\n\n\n\nAutonomous, first-order ODE models with a single variable can have only two types of behavior: a) \\(x(t)\\) eventually reaches a fixed point and remains there; b) \\(x(t)\\) goes to \\(\\pm \\infty\\). This is a consequence of an important mathematical fact: if \\(dx(t)/dt = f(x(t))\\) and the function \\(f(x(t))\\) is “smooth” (e.g., continuously differentiable) then the solution for the ODE exists and is unique. This means that the equation can cross each point \\(x(t) = \\alpha\\) only once, or infinitely many times. In contrast, discrete models with a single variable can have very interesting behavior."
  },
  {
    "objectID": "ch1.html#discrete-time-models",
    "href": "ch1.html#discrete-time-models",
    "title": "Models for a single population",
    "section": "",
    "text": "We have so far analyzed models where the growth of a population is described by an ordinary differential equation. However, for particular situations, and especially for species with nonoverlapping generations, a discrete-time approach would be more suitable.\n\n\nTo understand whether a discrete model is stable, we analyze the plot of \\(x_{t+1}\\) against \\(x_t\\), superimposed on the diagonal (\\(x_{t+1}=x_{t}\\)). We use these two curves to “cobweb”:\n\nStarting from an initial condition \\(x_t=x(0)\\) (some point on the x-axis), we draw a line to the model’s projection of the population at the next time step (\\(x_{t+1}\\))\nWe then set \\(x_t=x_{t+1}\\) to obtain the population in the next time step. To speed the process along, rather than lifting our pencils to draw \\(x_{t+1}\\) at \\(x_t\\) on the x-axis, we can simply draw a horizontal line from \\(x_{t+1}\\) back to the diagonal (which shows \\(x_{t+1}=x_t\\)) and then move vertically to get the next \\(x_{t+1}\\)\nWith enough iterations, this process reveals whether the population converges to a fixed point or does something more elaborate, and if this trajectory involves oscillations. Note that at a fixed point, \\(x_{t+1}=x_t=x^\\star\\).\n\nWe can use this approach for any map (discrete-time model) of \\(x_{t+1}\\) to \\(x_t\\), although cobwebbing suffers the disadvantage of requiring a lot of manual labor to explore the asymptotic behavior. To explore its uses further, we’ll consider one of the most basic and important density-dependent, discrete-time models: the logistic map.\n\n\n\nThis is a model with a very similar formulation to the logistic growth ODE above:\n\\[\nx_{t+1} = r\\, x_t (1 - x_t)\n\\]\nWith \\(x_t &gt; 0\\) and \\(r &gt; 0\\). When \\(x_t &gt; 1\\), the population will decline; therefore it makes sense to start the population at a value \\(0&lt;x_0&lt;1\\). For these values, the population might grow only if \\(r &gt; 1\\) (i.e., we want \\(x_{t+1} &gt; x_t\\) for growth).\nLet’s try our hand at cobwebbing: set \\(x_0 = 1/2\\) and \\(r = 3/2\\). The cobwebbing plot becomes:\n\n\n\n\n\nshowing that the population declines and then stops at an equilibrium. We can compute the equilibrium by setting \\(x_{t+1} = x_t = x^\\star\\):\n\\[\n\\begin{aligned}\nx^\\star &= r\\, x^\\star (1 - x^\\star)\\\\\n1 &= r\\, (1 - x^\\star)\\\\\nx^\\star &= 1 - \\frac{1}{r}\n\\end{aligned}\n\\]\nThus, a feasible (positive) equilibrium is found only for \\(r &gt; 1\\), as expected. In the example above, the equilibrium is reached without oscillations. Let’s try the cobweb for a larger \\(r = 5/2\\)\n\n\n\n\n\nNow the solution \\(x^\\star = 1 - \\frac{2}{5} = \\frac{3}{5}\\) is reached after oscillating above and below this value.\n\n\n\nWe want to determine whether \\(x^\\star\\) is stable for a given map (discrete-time model) \\(x_{t+1} = f(x_t)\\), with \\(f(x^\\star)=x^\\star\\). In particular, we want to determine whether when we initialize the system close to \\(x^\\star\\) we converge back to \\(x^\\star\\).\nTake \\(x_t = x^\\star + \\epsilon_t\\), where \\(\\epsilon_t\\) is small. Then we have\n\\[\n\\begin{aligned}\nx_{t+1} &= f(x_t)\\\\\nx^\\star + \\epsilon_{t+1} &= f(x^\\star + \\epsilon_t)\\\\\nx^\\star + \\epsilon_{t+1} &\\approx f(x^\\star) + \\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star} (x_t - x^\\star) \\\\\nx^\\star + \\epsilon_{t+1} &\\approx x^\\star + \\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star} \\epsilon_t\\\\\n\\epsilon_{t+1} &\\approx \\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star} \\epsilon_t\\\\\n\\end{aligned}\n\\]\nwhich is the very first model we have written. We have:\n\\[\n\\epsilon_{t+k} = \\rho^{k} \\epsilon_t\n\\]\nwith \\(\\rho = \\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star}\\). We have that\n\\[\n\\lim_{k \\to \\infty} \\epsilon_{t+k} = 0 \\quad \\text{if} \\, |\\rho| &lt; 1\n\\]\nThus, the equilibrium is stable if and only if the absolute value of \\(\\left. \\dfrac{d f(x_t)}{dx_t}\\right|_{x^\\star}\\) is less than 1. If this value is greater than 1, then the equilibrium is unstable: small perturbations will amplify (at least initially); if the value is exactly 1, the analysis is inconclusive, and we might want to consider including higher-order terms in the Taylor expansion above.\nExample\nTake \\(r = 2\\), and show that the equilibrium \\(x^\\star = 1/2\\) is stable. We take the derivative:\n\\[\n\\rho = \\left.\\dfrac{d f(x_t)}{d x_t} \\right|_{x^\\star} = r \\left. \\dfrac{d (x_t (1- x_t))}{d x_t}\\right|_{x^\\star} = \\left. r (1 - 2 x_t)\\right|_{x^\\star}\n\\]\nand substitute the values of \\(r\\) and \\(x_t = x^\\star = 1/2\\). We obtain \\(\\rho = 0\\) and thus the equilibrium is stable. In fact, we see that, for any value of \\(r &gt; 0\\) leading to a feasible equilibrium, we have:\n\\[\n\\rho = r \\left(1 - 2 \\left(1 - \\frac{1}{r} \\right) \\right) = 2 - r\n\\]\nand thus whenever \\(|2 - r| &lt; 1\\) we have a stable equilibrium. This is true whenever \\(3&gt; r &gt;1\\).\n\n\n\nIf we make \\(r\\) even larger, we find new behavior. For example, take \\(r = 10/3\\), \\(x_0 = 3/4\\)\n\n\n\n\n\nAfter a few oscillations, the system sets into a cycle, alternating between two values. This is best seen by plotting a time-series, in which we have the (discrete) time in the x-axis, and the value \\(x_t\\) on the y-axis:\n\n\n\n\n\nWhat are the two values? To find them, we can set \\(x_{t+2} = x_{t}\\) making sure that \\(x_{t+1} \\neq x_t\\). Take:\n\\[\n\\begin{aligned}\nx_{t+2} &= x_t\\\\\nf(x_{t+1}) &= x_t\\\\\nf(f(x_t)) &= x_t\\\\\nf^{(2)}(x_t) &= x_t\n\\end{aligned}\n\\]\nFor the logistic map, we have:\n\\[\n\\begin{aligned}\nx_t &= r\\,x_{t+1}\\,(1 - x_{t+1})\\\\\n&= r\\, r\\, x_t (1 - x_t)\\, (1 -  r\\, x_t (1 - x_t))\\\\\n&= r^2 x_t (1-x_t) (1 -  r\\, x_t (1 - x_t))\n\\end{aligned}\n\\]\nWhen we discard the solution \\(x_t =0\\), we obtain the cubic polynomial:\n\\[\n-r^3 x_t^3+2 r^3 x_t^2-(r+1) r^2 x_t+r^2-1= 0\n\\]\nWe can factor out the solution \\(x_t = 1 - \\frac{1}{r}\\), which we know already, obtaining:\n\\[\n\\begin{aligned}\nr^3 x_t^2 - r^2 (1 + r) x_t + r (1 + r) &= 0\\\\\nr^2 x_t^2 - r (1 + r) x_t + (1 + r) &= 0\n\\end{aligned}\n\\]\nYielding:\n\\[\nx_c = \\dfrac{r +1 \\pm \\sqrt{(r-3) (r+1)}}{2 r}\n\\]\nBoth values are greater than zero whenever \\(r \\geq 3\\). We can investigate the stability of the cycle, we can take the derivative w.r.t. \\(x_t\\) of \\(f^{(2)}(x_t)\\), and plug in one of the two values above:\n\\[\n\\begin{aligned}\n\\rho &= \\left.\\dfrac{d f^{(2)}(x_t)}{d x_t} \\right|_{x_c}\\\\\n&= \\left. \\left(\\dfrac{d}{d x_t} r^2 x_t (1-x_t) (1 -  r\\, x_t (1 - x_t)) \\right)\\right|_{x_c}\\\\\n&= \\left. (r^2 (1 - 2 x_t)(1 - 2 r x_t(1-x_t))) \\right|_{x_c}\n\\end{aligned}\n\\]\nSubstituting the larger value of \\(x_c\\), we eventually find:\n\\[\n\\rho = 4 - r (r - 2)\n\\]\nThe period-2 cycle is stable whenever \\(|\\rho| &lt; 1\\). If we assume that \\(r \\geq 3\\) (required for the existence of the cycle in the first place), we have:\n\\[\n3 &lt; \\rho &lt; 1 + \\sqrt{6} \\approx 3.45\n\\]\nThe period-2 orbits are therefore stable in this range. What happens beyond this value of \\(r\\)? Take \\(r = 3.5\\) and cobweb:\n\n\n\n\n\nNow we have that the system oscillates between four values, as seen from the time-series (where we have removed the first 250 time steps for clarity):\n\n\n\n\n\nNow we have a period-4 solution, which is stable until \\(1 + \\sqrt{6} &lt; r &lt; 3.701\\), at which point we find period-8 cycles:\n\n\n\n\n\n\n\n\nThe system can yield cycles of period three. Take \\(r = 1 + 2 \\sqrt{2}\\), and plot the time series:\n\n\n\n\n\nA famous result (Sharkovsky’s theorem, Ukrainian Math J, 1964) states that if a map has cycles of period 3, then it must have cycles of every other period. Li and Yorke (“Period Three Implies Chaos”. Am. Math. Monthly, 1975) showed that indeed a period-three implies infinitely many trajectories that do not have a period, and oscillate without ever completing a cycle. We call this phenomenon chaos.\nChaos is aperiodic long-term behavior in a deterministic system that exhibits sensitive dependence to initial conditions. In particular, one can prove that in a chaotic regime, if we start with two initial conditions that are very close to each other (their distance being \\(\\Delta x_0\\)) we eventually find very different trajectories. In particular, when we have chaos:\n\\[\n|\\Delta x(t)| \\approx e^{\\lambda t}|\\Delta x_0|\n\\]\nwith \\(\\lambda&gt;0\\) (the Lyapunov exponent).\nTo show this behavior, let’s plot two trajectories for the system when \\(r = 3.675\\) and \\(x_0 = 0.5\\) or \\(x_0 = 0.4999\\):\n\n\n\n\n\n\n\n\nAll these results can be summarized in a beautiful graph. We build it as follows:\n\npick a value of \\(r\\)\nstarting from an arbitrary point, \\(x_0 = 1/2\\), compute \\(x_t\\) for a large number of points, and discard the first part of the time series (transient dynamics)\nlocate and record the minima and maxima of the time series\nplot \\(r\\) (x-axis) against the location of the minima and maxima (y-axis)\n\nIf the trajectories converge to an equilibrium, we will find a single point; if trajectories converge to a period-2 cycle, we will find two points; etc.\n\nlogistic_map_ts &lt;- function(r, max_time = 3000, discard = 2000){\n  ts &lt;- accumulate(.x = rep(1/2, max_time), .f = function(xt, xtp1) r * xt * (1-xt))[discard:max_time]\n  # discard points at which the trajectory repeats\n  difference &lt;- abs(ts - ts[1])\n  zz &lt;- which(difference &lt; 10^-6)\n  if(length(zz) &gt; 1) ts &lt;- ts[1:zz[2]]\n  return(tibble('x' = ts, 'r' = r))\n}\n# load results if available\nif (file.exists(\"data/logistic_bifurcation.RData\")){\n  load(\"data/logistic_bifurcation.RData\")\n} else {\n  # compute the results (this will take some time...)\n  bifurcation_logistic_map &lt;- map_df(.x = seq(2.95, 3.99, by = 0.001), \n                                     .f = logistic_map_ts)  \n  # and save the file\n  save(bifurcation_logistic_map, file = \"data/logistic_bifurcation.RData\")\n}\nggplot(bifurcation_logistic_map) + \n  aes(x = r, y = x) + \n  geom_point(size = 0.005, alpha = 0.2) + \n  theme_bw() + \n  xlab(expression(r)) + ylab(expression(x[t]))\n\n\n\n\n\n\n\n\n\n\nExercise: Ricker model\n\n\n\n\n\nThis period-doubling cascade to chaos is common to several models. Draw the bifurcation diagram for the Ricker model:\n\\[\nx_{t+1} = x_t e^{r(1-x_t)}\n\\]\nagain taking values of \\(r\\) between 1.95 and 4, and values of \\(x_0\\) between 0 and 1.\n\n\n\n\n\n\n\n\n\nEuler’s method\n\n\n\n\n\nWhen we want to compute trajectories for a differential equations, we face the problem that typically the equations cannot be solved. Computers get around this issue by carefully computing the trajectory for a discrete-time model. The simplest case is that of Euler’s method.\nWe want to compute the solution of \\(dx(t)/dt = f(x(t))\\). For sufficiently small \\(\\Delta t\\), we can Taylor-expand \\(x(t_0 + \\Delta t)\\) around \\(t_0\\), obtaining:\n\\[\nx(t_0 + \\Delta t) \\approx x(t_0) + \\left. \\dfrac{d x(t)}{dt}\\right|_{t_0} \\Delta t\n\\]\nwe know the value of \\(x(t_0) = x_0\\), and the function \\(d x(t) / dt = f(x(t))\\), and as such:\n\\[\nx(t_0 + \\Delta t) \\approx x_0 + \\Delta t \\, f(x_0)\n\\]\nWe iterate this procedure again and again, drawing our trajectory. Naturally, taking smaller \\(\\Delta t\\) we should get better approximations, from a mathematical standpoint. In fact, one can show that the error we’re making is proportional to \\(\\Delta t\\). However, reducing \\(\\Delta t\\) has two undesirable effects: first, the calculation time will increase accordingly; second, because computers have limited precision when representing numbers, at each step we will make round off errors, and these will accumulate faster when the step size is small.\nIn practice, when we use Euler’s method we assume that \\(f(x)\\) is fixed during the step \\(\\Delta t\\) (which we now is generally not true). We can average across two points, yielding the so-called midpoint method:\n\\[\n\\begin{aligned}\ny_{t + \\Delta t} &= x_t + \\Delta_t f(x_t)\\\\\nx_{t + \\Delta t} &= x_t + \\frac{1}{2}(f(x_t) + f(y_{t + \\Delta t}))\n\\end{aligned}\n\\]\nwhere \\(y_{t + \\Delta t}\\) is what computed using Euler’s method, and the slope for the actual step is taken to be the average \\(f(x)\\) at the beginning and end of the step. One can show that the error is now proportional to \\((\\Delta t)^2\\), which is a good improvement.\nThe same logic applies when we take several intermediate steps, and average across them, as done for the Runge-Kutta methods.\nIn fact, the best software tries to pick small \\(\\Delta t\\) when \\(x(t)\\) is changing rapidly, and larger \\(\\Delta t\\) when \\(x(t)\\) is changing slowly. These adaptive-step methods are the state-of-the-art, and are implemented in the package deSolve in R."
  },
  {
    "objectID": "ch1.html#classic-papers",
    "href": "ch1.html#classic-papers",
    "title": "Models for a single population",
    "section": "",
    "text": "A brief paper discussing how to build models in biology:\n\nRichard Levins, 1966. The strategy of model building in population biology. American Scientist 54:421-431\n\nThis paper introduces the famous metapopulation model:\n\nRichard Levins, 1969. Some demographic and genetic consequences of environmental heterogeneity for biological control. Bull. Entomol. Soc. Am. 15:237–240.\n\nThis paper shows the onset of chaos in simple discrete-time models:\n\nRobert M. May, 1976. Simple mathematical models with very complicated dynamics. Nature 261:459-467\n\nThis paper discusses how simple models relates to experimental data on population growth:\n\nMichael P. Hassell, John H. Lawton, Robert M. May, 1976. Patterns of dynamical behavior in single species populations. Journal of Animal Ecology 45:471-486"
  },
  {
    "objectID": "ch2.html",
    "href": "ch2.html",
    "title": "Models for two populations",
    "section": "",
    "text": "To start our exploration of more complex models, we consider two populations (\\(X\\) and \\(Y\\)), growing logistically on their own, that interact competitively:\n\\[\n\\begin{cases}\n\\dfrac{dX}{d\\tau} = X(r_1 - B_{11} X - B_{12}Y)\\\\\n\\dfrac{dY}{d\\tau} = Y(r_2 - B_{21} X - B_{22}Y)\\\\\n\\end{cases}\n\\]\nWhere all parameters are positive; the \\(r_i\\) are the intrinsic growth rates, and \\(B_{ij}\\) measures how much the growth of \\(i\\) is decreased when adding a unit of population \\(j\\).\n\n\n\n\n\n\nMatrices and vectors\n\n\n\n\n\nA matrix \\(A\\) is a rectangular arrays of numbers (the entries of the matrix, \\(A_{ij}\\)). For this class, we will consider matrices with either real entries, \\(A_{ij} \\in \\mathbb R; A_{ij} = \\alpha\\), or complex entries, \\(A_{ij} \\in \\mathbb C; A_{ij}=\\alpha + i \\beta\\). The size of the matrix is given by the number of rows \\(n\\) and the number of columns \\(m\\). To show the size explicitly, we use \\(A_{n \\times m}\\). If \\(n = m\\) the matrix is square.\nA (column) vector \\(b\\) is a matrix with a single column (i.e., size \\(n \\times 1\\)), and a row vector \\(a^T\\) is of size \\(1 \\times m\\). We use \\({}^T\\) to denote transposition, an operation that turns the rows into columns and vice versa: \\((A^T)_{ij} = A_{ji}\\); if \\(A_{n \\times m}\\), then \\(A^{T}_{m \\times n}\\).\nBasic operations that can be performed with matrices:\n\nTwo matrices can be added only if they have the same size \\(A + B = C\\), with \\(C_{ij} = A_{ij} + B_{ij}\\).\nTwo matrices can be multiplied if the number of columns of the first matrix matches the number of rows of the second matrix: \\(A_{n \\times m} B_{m \\times l} = C_{n \\times l}\\) with \\(C_{ij} = \\sum_{k = 1}^{m} A_{ik} B_{kj}\\). In general, \\(AB \\neq BA\\): matrices do not generally commute.\nIf two matrices have the same size, we can also take the Hadamard (element-by-element) product \\(A \\circ B = C\\), with \\(C_{ij} = A_{ij} B_{ij}\\).\n\nIn R, a vector can be defined by concatenation v &lt;- c(1,2,3), and a matrix by reshaping a vector M &lt;- matrix(c(1,2,3,4), 2, 2) note that the entries are filled by column; if you want to fill them by row use M &lt;- matrix(c(1,2,3,4), 2, 2, byrow = TRUE). The Hadamard product is coded as *, and the matrix multiplication as %*%\n\n\n\nWe can gather the variables and the parameters into two vectors and a matrix:\n\\[\nZ = (X, Y)^T\\quad r = (r_1, r_2)^T\\quad B = \\begin{pmatrix}\nB_{11} & B_{12}\\\\\nB_{21} & B_{22}\n\\end{pmatrix}\n\\]\nThus, the dynamics can be written as:\n\\[\n\\dfrac{d Z_i}{d\\tau} = Z_i (r_i - \\sum_j B_{ij} Z_j)\n\\]\nor, in vector form:\n\\[\n\\dfrac{dZ}{d\\tau} = D(Z)(r - BZ)\n\\]\nNon-dimensionalization\nWe define:\n\\[\nx = c_1 X \\quad y = c_2 Y \\quad t = c_3 \\tau\n\\]\nobtaining:\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x(c_3 r_1  - c_1 c_3 B_{11} x - c_2 c_3 B_{12}y)\\\\\n\\dfrac{dy}{dt} = y(c_3 r_2 - c_1  c_3 B_{21} x - c_2 c_3 B_{22}y)\\\\\n\\end{cases}\n\\]\nA convenient choice is:\n\\[\nc_3 = \\dfrac{1}{r_1}\\quad c_1 = \\dfrac{r_1}{B_{11}}\\quad c_2 = \\dfrac{r_1}{B_{22}}\n\\]\nYielding:\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x\\left(1  - x - \\dfrac{B_{12}}{B_{22}}y \\right)\\\\\n\\dfrac{dy}{d\\tau} = y\\left(\\dfrac{r_2}{r_1} - \\dfrac{B_{21}}{B_{11}} x - y \\right)\\\\\n\\end{cases}\n\\]\nWe define the ratio of intrinsic growth rates \\(\\rho = r_2 / r_1\\) and the ratio between the effect of \\(y\\) on the growth of \\(x\\) and the effect on itself \\(A_{12} = B_{12} / B_{22}\\) and similarly \\(A_{21} = B_{21} / B_{11}\\), obtaining:\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x\\left(1  - x - A_{12 }y \\right)\\\\\n\\dfrac{dy}{d\\tau} = y\\left(\\rho - A_{21} x - y \\right)\\\\\n\\end{cases}\n\\]\nEquilibria\nThe system has a trivial equilibrium \\((x^\\star, y^\\star) = (0,0)\\), in which both species are absent. If \\(y\\) is absent, we obtain the marginal equilibrium \\((x^\\star, y^\\star) = (1,0)\\), and if \\(x\\) is absent, we have \\((x^\\star, y^\\star) = (0, \\rho)\\). Finally, we can have a coexistence equilibrium, as long as the two terms in parenthesis are simultaneously zero:\n\\[\n\\begin{cases}\n1-x^\\star-A_{12}y^\\star = 0\\\\\n\\rho - A_{21} x^\\star - y^\\star = 0\n\\end{cases}\n\\]\nSolving the first equation for \\(x^\\star\\), we obtain \\(x^\\star = 1 - A_{12} y^\\star\\); plugging this solution into the second equation yields:\n\\[\n\\begin{aligned}\n\\rho - A_{21} + A_{12}A_{21} y^\\star - y^\\star &= 0\\\\\ny^\\star &= \\dfrac{\\rho - A_{21}}{1 - A_{12}A_{21}}\n\\end{aligned}\n\\] and correspondingly:\n\\[\nx^\\star = \\dfrac{1 - A_{12} \\rho}{1 - A_{12}A_{21}}\n\\]\nIf both values of \\(x^\\star\\) and \\(y^\\star\\) are positive, we have a coexistence equilibrium, if not then the point lies outside the nonnegative orthant \\(\\mathbb R^{2}_{0+}\\), and thus cannot be reached by the dynamics.\n\n\n\n\n\n\nSolving linear systems\n\n\n\n\n\nIn the equations above, either \\(x\\) (\\(y\\)) is zero, or the term in parenthesis is zero. If we define:\n\\[\nz = (x,y)^T \\quad s = (1, \\rho)^T \\quad A = \\begin{pmatrix}\n1 & A_{12}\\\\\nA_{21} & 1\n\\end{pmatrix}\n\\]\nwe have that both terms in parenthesis are simultaneously zero whenever:\n\\[\nAz^\\star = s\n\\]\nYou can solve a system of linear equations by inverting the matrix \\(A_{n \\times n}\\). A matrix \\(A\\) is called invertible if there is a matrix \\(B\\) such that:\n\\[\nAB = BA = I_n\n\\] where \\(I_n\\) is the identity matrix, a matrix with zero everywhere but the diagonal, and with the entries on the diagonal being all 1. The identity matrix is the neutral matrix for multiplication: \\(AI = IA = A\\).\nIf such a matrix \\(B\\) exists, it is called the inverse of \\(A\\), written as \\(A^{-1}\\). If a matrix is not invertible, it is called singular. For matrices with real or complex entries, the necessary and sufficient condition for invertibility is that the determinant of the matrix \\(\\det A \\neq 0\\).\nThe determinant of a \\(2 \\times 2\\) matrix \\(A\\) can be computed as:\n\\[\nA = \\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\\quad \\det A = ad - bc\n\\]\nComputing a matrix inverse is typically quite involved. For a \\(2 \\times 2\\) matrix, you can write:\n\\[\nA^{-1} = \\dfrac{1}{ad - bc}\\begin{pmatrix}\nd & -b \\\\\n-c & a\n\\end{pmatrix}\n\\]\nFor the Lotka-Volterra system we have:\n\\[\n\\det A = 1 - A_{12} A_{21}\n\\]\nwhen the determinant is not zero, then\n\\[\n\\begin{aligned}\nA z^\\star &= s\\\\\nA^{-1} Az^\\star &= A^{-1}s\\\\\nI z^\\star &= A^{-1}s\\\\\nz^\\star &= A^{-1}s\\\\\nz^\\star &= \\dfrac{1}{1-A_{12}A_{21}}\\begin{pmatrix}\n1 & -A_{21}\\\\\n-A_{12} &1\n\\end{pmatrix} \\begin{pmatrix}\n1\\\\\n\\rho\n\\end{pmatrix}\\\\\nz^\\star &= \\dfrac{1}{1-A_{12}A_{21}}\\begin{pmatrix}\n1 - A_{21} \\rho\\\\\n\\rho - A_{12}\n\\end{pmatrix}\n\\end{aligned}\n\\]\nIn R, you can solve a system of equation using solve(A, b) where A is a square, invertible matrix, and b is a vector of appropriate size.\n\n\n\nThus, the model has three or four equilibria, depending on the parameters. Another way to see this is to think about the values of \\(y\\) making \\(dx/dt = 0\\), and viceversa.\nZero-growth isoclines\nTake the first equation, and set it to zero:\n\\[\nx\\left(1  - x - A_{12 }y \\right) = 0\n\\]\nequality is obtained when either \\(x =0\\) or \\(y = (1-x)/ A_{12}\\). This equation defines a line in the \\((x,y)\\) plane, called the phase plane. Similarly, if we take the second equation\n\\[\ny\\left(\\rho - A_{21} x - y \\right) = 0\n\\]\nwe see that this is zero whenever \\(y = 0\\) or when \\(y = \\rho - A_{21}x\\), another line in the phase plane. If the two lines meet in the positive quadrant, then we have the possibility of coexistence.\nFor example, take \\(\\rho = 1\\), \\(A_{12} = 1/3\\) and \\(A_{21} = 1/4\\):\n\n\n\n\n\nEach species grows at points that are below its zero-growth isocline, and declines at points that are above it. Thus, for each point in the phase plane we can determine the general direction of the trajectories:\n\n\n\n\n\nWe can use these arrows to classify the stability of the equilibria. For example, around \\((0,0)\\) arrows move away from the point; it is thus an unstable equilibrium. Similarly, the two marginal points have arrows pointing away from them, and are thus unstable; around the coexistence equilibrium, all arrows point back to it, indicating stability.\nIn fact, we can show trajectories converging to the coexistence equilibrium:\n\nglv2_plot_all(parms = parms_c1, \n              plot_isoclines = TRUE, \n              plot_flow = TRUE, \n              plot_trajectories = TRUE,\n              initial_conditions = matrix(c(0.01, 0.012, \n                                            1.5, 0.02,\n                                            0.1, 1.6,\n                                            1.5, 1.5), \n                                          4, 2, byrow = TRUE),\n              xlims = c(0,2), ylims = c(0,2), arrow_length = 0.15)\n\n\n\n\nDepending on the value of the parameters, we have four cases; two in which the two lines do not meet in the positive orthant; and two cases in which they do. In particular:\n\n\n\n\n\n\n\n\n\n\n\n\nEigenvalues and eigenvectors\n\n\n\n\n\nThe product of a matrix and a vector is another vector:\n\\[\nA x = b\n\\]\nEach matrix is associated with certain special vectors such that:\n\\[\nA v = \\lambda v\n\\] i.e., multiplying the vector with the matrix simply scales all the entries of the vector by a constant, \\(\\lambda\\). When this is the case, we say that \\(v\\) is an eigenvector of \\(A\\), with associated eigenvalue \\(\\lambda\\). Note that eigenvectors are defined up to a constant: if \\(v\\) is an eigenvector of \\(A\\), and \\(w = \\gamma v\\), then:\n\\[\nAw = \\gamma A v= \\gamma \\lambda v = \\lambda w\n\\]\nA matrix \\(A\\) is called diagonalizable if there exists an invertible matrix \\(P\\) such that \\(PAP^{-1} = D\\), where \\(D\\) is a diagonal matrix, i.e., having nonzero values only on the diagonal.\nExample\n\\[\nA = \\begin{pmatrix}\n1 & 2\\\\\n4 & 3\n\\end{pmatrix}\\quad v = \\begin{pmatrix}\n1\\\\\n2\n\\end{pmatrix}\\quad\nAv = \\begin{pmatrix}\n5\\\\\n10\n\\end{pmatrix} = 5 v\n\\]\nThen \\(v= (1,2)^T\\) is an eigenvector of \\(A\\) with eigenvalue \\(\\lambda = 5\\).\nA diagonalizable matrix can be written as:\n\\[\nA = Q \\Lambda Q^{-1}\n\\]\nwhere each of the columns of \\(Q\\) is an eigenvector of \\(A\\), and \\(\\Lambda\\) is a diagonal matrix with the corresponding eigenvalues. This factorization (writing a matrix as a product of other matrices) is called the eigendecomposition of \\(A\\).\nYou can see that:\n\\[\n\\begin{aligned}\nA v &= \\lambda v\\\\\nA Q &= Q \\Lambda\\\\\nA &= Q \\Lambda Q^{-1}\n\\end{aligned}\n\\]\nThe trace of a matrix is the sum of the diagonal entries, it is also the sum of the eigenvalues:\n\\[\n\\text{Tr}\\, A = \\sum_i A_{ii} = \\sum_i \\lambda_i\n\\]\nThe determinant of a matrix is the product of its eigenvalues (and thus a singular matrix has at least one zero eigenvalue):\n\\[\n\\det A = \\prod_i \\lambda_i\n\\]\nA diagonalizable matrix of size has \\(n\\) eigenvalues (not necessarily distinct) and \\(n\\) corresponding eigenvectors. The number of nonzero eigenvalues is the rank of the matrix.\nComputing the eigenvalues of a matrix is very involved, and can be done analytically only for small matrices. The eigenvalues of \\(A\\) are the zeros of the characteristic polynomial:\n\\[\n\\det (A - \\lambda I) = p(\\lambda)\n\\]\nA matrix with real entries has eigenvalues that are either real, \\(\\lambda_i = \\alpha\\), or complex \\(\\lambda = \\alpha + i \\beta\\); the complex root are paired: \\(\\lambda_{i,j} = \\alpha \\pm i \\beta\\) (conjugate complex eigenvalues). A symmetric matrix \\(A = A^T\\) has only real roots; a skew-symmetric matrix \\(A = -A^T\\) has roots with real part zero.\nThe diagonal matrix \\(D(\\alpha)\\) has eigenvalues \\(\\alpha\\).\nThe eigenvalues of the inverse \\(A^{-1}\\) are the reciprocals of the eigenvalues of \\(A\\): if \\(A\\) has eigenvalue \\(\\lambda\\), then \\(A^{-1}\\) has eigenvalue \\(1/\\lambda\\). The eigenvectors are the same. The transpose \\(A^T\\) has the same eigenvalues of \\(A\\); the eigenvectors are \\(A^T = (Q \\Lambda Q^{-1})^T = {Q^{-1}}^T \\Lambda Q^T\\)\nIf a matrix has only positive, real eigenvalues it is positive definite, if it has only nonnegative eigenvalues it is positive semi-definite; if it has only negative eigenvalues it is negative definite.\nIf \\(A\\) is positive definite, then\n\\[\n\\sum_i \\sum_j A_{ij} x_i x_j = x^T A x &gt; 0 \\quad \\forall x \\neq 0\n\\]\nIf \\(A\\) is symmetric, then it can be decomposed as:\n\\[\nA = A^T = Q \\Lambda Q^T\n\\]\ni.e., in this case \\(Q^{-1} = Q^T\\).\nFinding eigenvalues for \\(2\\times2\\) matrix\nThe matrix\n\\[\nA = \\begin{pmatrix}\na & b\\\\\nc & d\n\\end{pmatrix}\n\\]\nhas \\(\\text{Tr}\\, A = a+ d\\) and \\(\\det A = ad - bc\\). Then:\n\\[\n\\begin{cases}\n\\lambda_1 + \\lambda_2 = a + d\\\\\n\\lambda_1 \\lambda_2 = ad - bc\n\\end{cases}\n\\]\nand thus\n\\[\n\\lambda = \\dfrac{a + d \\pm \\sqrt{4bc + (a-d)^2}}{2}\n\\]\nThe eigenvectors can be found by setting one of the entries to an arbitrary value (e.g., \\(v_1 = 1\\)), and solving the equations:\n\\[\nAv = \\lambda v\n\\]\nIn R, you can compute the eigenvalues and eigenvectors of a matrix \\(A\\) as eA &lt;- eigen(A); the function returns a list with the matrix of eigenvectors stored in eA$vectors and the vector of eigenvalues in eA$values.\n\n\n\n\n\nIn the previous lectures, we have approximated the behavior of \\(f(x)\\) around the equilibrium, to determine whether small perturbations would be buffered by the system. We can perform the same type of analysis here. However, now \\(dx_i / dt = f_i(x)\\) is a function of multiple populations, and therefore we need to Taylor-expand multivariate functions.\nIn analogy with the Talyor-expansion of functions of a single variable, we can write:\n\\[\nf_i(x^\\star + \\Delta x) = f_i(x^\\star) + \\sum_k \\left. \\dfrac{\\partial f_i(x)}{\\partial x_k} \\right|_{x^\\star} \\Delta x_k + \\dfrac{1}{2} \\sum_{k}\\sum_{l} \\left. \\dfrac{\\partial^2 f_i(x)}{\\partial x_k \\partial x_l} \\right|_{x^\\star} \\Delta x_k \\Delta x_l + \\cdots\n\\] As before, \\(f_i(x^\\star) = 0\\), and if we take only the second term (i.e., the term linear in \\(\\Delta x\\)) we can approximate the function as:\n\\[\nf_i(x^\\star + \\Delta x) \\approx \\sum_k \\left. J_{ik} \\right|_{x^\\star} \\Delta x_k\n\\]\nWhere we have defined the Jacobian matrix \\(J\\):\n\\[\nJ_{ij} = \\dfrac{\\partial f_i(x)}{\\partial x_j}\n\\] For each equilibrium in the system, we can obtain a different community matrix (the name is due to Levins) \\(M\\):\n\\[\nM = \\left. J \\right|_{x^\\star}\n\\]\nAs such, a system of ODEs has a single Jacobian, and as many community matrices as there are equilibria. As before, we assume that we have slightly perturbed the system at equilibrium, \\(x(t) = x^\\star + \\Delta x\\), where \\(\\Delta x\\) is assumed to be small, and then we approximate the dynamics:\n\\[\n\\dfrac{d\\Delta x}{dt} \\approx \\left. J \\right|_{x^\\star} \\Delta x\n\\]\ni.e., we need to solve a linear system of ODEs.\n\n\n\n\n\n\nSolving systems of linear ODEs\n\n\n\n\n\nConsider the system of first-order, autnonomous ODEs:\n\\[\n\\dfrac{dx}{dt} = Ax\n\\]\nIf the matrix \\(A\\) is diagonalizable, we can decompose the matrix as:\n\\[\nA = Q \\Lambda Q^{-1}\n\\]\nWe define a new system of equations, by changing the variables:\n\\[\ny = Q^{-1}x\\quad x = Q y\n\\]\nThen, by chain rule:\n\\[\n\\dfrac{dy}{dt} = Q^{-1} \\dfrac{d x}{dt} = Q^{-1}Q \\Lambda Q^{-1} x= \\Lambda Q^{-1} x = \\Lambda y\n\\]\nWe have decoupled all equations: now the \\(y_i\\) grow or decline independently of each other.\n\\[\n\\dfrac{dy_i}{dt} = \\lambda_i y_i\n\\]\nThis is in fact the equation for the exponential growth/decay, with solution \\(y_i(t) = y(0) e^{\\lambda_i t}\\).\nWe can bring these solutions back to the original form:\n\\[\ny(t) = e^{\\Lambda t} y(0)\n\\]\nwhere \\(e^\\Lambda t\\) is a diagonal matrix:\n\\[\ne^{\\Lambda t}= \\begin{pmatrix}\ne^{\\lambda_1 t} & 0 & \\cdots &0\\\\\n0 & e^{\\lambda_2 t} & \\cdots &0\\\\\n\\cdots & \\cdots & \\cdots & \\cdots\\\\\n0 & 0 & \\cdots & e^{\\lambda_n t}\\\\\n\\end{pmatrix}\n\\]\nThen:\n\\[\nx(t) = Q y(t) = Q e^{\\Lambda t} y(0) = Q e^{\\Lambda t} Q^{-1} x(0)\n\\]\nAllowing to easily compute the solution for any linear systems of ODEs.\nStability of the origin\nSuppose that \\(\\lambda_i\\) is a real number; then \\(\\lim_{t \\to \\infty}e^{\\lambda_i t} = 0\\). If \\(\\lambda_i\\) is positive, on the other hand, then \\(\\lim_{t \\to \\infty}e^{\\lambda_i t} = \\infty\\). Thus, if any of the \\(\\lambda_i &gt; 0\\), the system will move to \\(\\infty\\) in the direction specified by the corresponding eigenvector.\nWhenever \\(\\lambda_i\\) is complex (e.g., generically, when \\(A\\) is not symmetric), then we need to consider:\n\\[\ne^{\\alpha t + i \\beta t} = e^{\\alpha t} e^{i \\beta t} = e^{\\alpha t} (\\cos \\beta + i \\sin \\beta )t\n\\]\nwhere we have used Euler’s identity. Importantly, \\((\\cos \\beta + i \\sin \\beta )\\) is bounded, and in fact its real (imaginary) part is \\(\\leq 1\\). Then, \\(\\lim_{t \\to \\infty} e^{\\alpha t + i \\beta t} = 0\\) if \\(\\alpha &lt; 0\\).\nTherefore, the vector \\(0_n\\) is an asymptotically stable equilibrium of the system \\(\\dfrac{dx}{dt} = A x\\) if and only if all the eigenvalues of \\(A\\) have negative real part.\n\n\n\nThus, to probe the local asymptotic stability of each of the equilibria, we can:\n\nCalculate the Jacobian matrix, \\(J\\)\nPlug in an equilibrium, obtaining the corresponding community matrix \\(M\\)\nCompute the eigenvalues of \\(M\\), \\(\\lambda_i\\)\nIf all the eigenvalues have negative real part, \\(\\Re (\\lambda_i) &lt; 0\\), then the equilibrium is locally asymptotically stable\n\nFor example, for the system above, we have:\n\\[\n\\begin{cases}\nf_x(x,y) = x- x^2 - A_{12}xy \\\\\nf_y(x,y) = \\rho y - A_{21} xy - y^2\n\\end{cases}\n\\]\n\\[\nJ = \\begin{pmatrix}\n(1 - 2 x - A_{12} y) & -A_{12} x\\\\\n-A_{21} y & (\\rho - 2 y - A_{21} x)\n\\end{pmatrix}\n\\] For \\((x^\\star, y^\\star) = (0,0)\\), we obtain:\n\\[\nM = \\begin{pmatrix}\n1 & 0\\\\\n0 & \\rho\n\\end{pmatrix}\n\\]\nwith eigenvalues \\(1\\) and \\(\\rho&gt;0\\): the equilibrium is unstable.\nFor the marginal equilibrium \\((x^\\star, y^\\star) = (1,0)\\), we obtain:\n\\[\nM = \\begin{pmatrix}\n-1  & -A_{12} \\\\\n0 & \\rho - A_{21}\n\\end{pmatrix}\n\\]\nThe eigenvalues are \\(-1\\) and \\(\\rho - A_{21}\\) and thus the equilibrium is stable whenever \\(\\rho &lt; A_{21}\\) and unstable when \\(\\rho &gt; A_{21}\\).\nFor the other marginal equilibrium \\((x^\\star, y^\\star) = (0,\\rho)\\), we obtain:\n\\[\nM = \\begin{pmatrix}\n1 - A_{12} \\rho & 0\\\\\n-A_{21} \\rho & -\\rho\n\\end{pmatrix}\n\\] with eigenvalues \\(-\\rho\\) and \\(1 - A_{12} \\rho\\). Thus, the equilibrium is stable whenever \\(1/\\rho &lt; A_{12}\\) and unstable when \\(1/\\rho &gt; A_{12}\\).\nFinally, whenever a feasible equilibrium \\((x^\\star, y^\\star) &gt; (0,0)\\) we have that the terms in parenthesis are zero. Thus \\((1 - x^\\star - A_{12} y^\\star) = 0\\) and \\((\\rho - y^\\star - A_{21} x^\\star)\\), yielding:\n\\[\nM = \\begin{pmatrix}\n- x^\\star & -A_{12} x^\\star\\\\\n-A_{21} y^\\star & -y^\\star\n\\end{pmatrix}\n\\]\nThe eigenvalues are:\n\\[\n\\lambda_{12} = \\dfrac{1}{2}\\left(-(x^\\star+y^\\star) \\pm \\sqrt{(x^\\star-y^\\star)^2 + 4 A_{12}A_{21} x^\\star y^\\star} \\right)\n\\]\nNote that if \\(A_{12}A_{21} = 1\\), then we have that the eigenvalues are \\(\\frac{1}{2}(-(x^\\star+y^\\star) \\pm (x^\\star+y^\\star))\\), and thus one of them is zero. Hence, the equilibrium is stable as long as \\(A_{12} A_{21} &lt; 1\\).\n\n\n\n\nWe have a prey who would grow exponentially when the predator is absent, and a predator that would decline exponentially when the prey is absent. The two species interact, thus allowing for their coexistence:\n\\[\n\\begin{cases}\n\\dfrac{dX}{d\\tau} = \\rho X - \\alpha X Y = X(\\rho - \\alpha Y)\\\\\n\\dfrac{dY}{d\\tau} = -\\delta Y + \\beta X Y = Y(-\\delta + \\beta X)\n\\end{cases}\n\\]\nwhere all parameters are positive. There are two equilibria: \\((X, Y) = (0, 0)\\) and \\((X, Y) = \\left(\\frac{\\delta}{\\beta}, \\frac{\\rho}{\\alpha} \\right)\\).\nNondimensionalization To simplify the equation (but maintain all its important features), we can define two new variables and a new time scale:\n\\[\nx = c_1 X \\quad y = c_2 Y \\quad t = c_3 \\tau\n\\]\nUsing the new variables, we write:\n\\[\n\\begin{cases}\n\\dfrac{c_1}{c_3}\\dfrac{dx}{dt} = c_1 x(\\rho - \\alpha c_2 y)\\\\\n\\dfrac{c_2}{c_3}\\dfrac{dy}{dt} = c_2 y(-\\delta + \\beta c_1 x)\n\\end{cases}\n\\] and thus\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x(c_3 \\rho - \\alpha c_2 c_3 y)\\\\\n\\dfrac{dy}{dt} = y(-c_3 \\delta + \\beta c_1 c_3 x)\n\\end{cases}\n\\]\nIt is convenient to take \\(c_3 = 1/\\rho\\), \\(c_2 = \\rho / \\alpha\\), and \\(c_1 = \\rho / \\beta\\), thus simplifying the system to:\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x(1 - y)\\\\\n\\dfrac{dy}{dt} = y(-\\frac{\\delta}{\\rho} + x) = y(-\\alpha + x)\n\\end{cases}\n\\]\nWe can therefore analyze the case in which we have only a single free parameter, \\(\\alpha = \\rho / \\delta &gt; 0\\). The equilibria are \\((x,y) = (0,0)\\) and \\((x, y) = (\\alpha, 1)\\).\nIsoclines of net zero growth. Clearly, the first equation is zero when either the prey is absent, or the predator is at \\(y = 1\\); the second equation is zero when either the predator is absent or the prey is at \\(x = \\alpha\\); we can draw the two lines in a plane where we have \\(x\\) on the x-axis and \\(y\\) on the y-axis. The feasible (positive) equilibrium will be at the intersection of the two lines:\n\n\n\n\n\nDirection of trajectories\nWe have four quadrants surrounding the positive equilibrium:\n\n\\(x &lt; \\alpha, y &lt; 1\\): in the bottom-left corner, we have \\(dx/dt &gt; 0\\) and \\(dy/dt &lt; 0\\); accordingly, the prey will grow and the predator decline.\n\\(x &gt; \\alpha, y &lt; 1\\): in the bottom-right corner, we have \\(dx/dt &gt; 0\\) and \\(dy/dt &gt; 0\\); accordingly, both populations will grow\n\\(x &gt; \\alpha, y &gt; 1\\): in the top-right corner, we have \\(dx/dt &lt; 0\\) and \\(dy/dt &gt; 0\\); the prey will decline, the predator grow\n\\(x &lt; \\alpha, y &gt; 1\\): in the top-left corner, we have \\(dx/dt &lt; 0\\) and \\(dy/dt &lt; 0\\); both populations will decline\n\nWe can show these directions visually, by computing \\((dx/dt, dy/dt)\\) at different values of \\((x, y)\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\nVito Volterra (1926) Fluctuations in the Abundance of a Species Considered Mathematically Nature 118 : 558-60\nGause, G.F. 1934. Experimental Analysis of Vito Volterra’S Mathematical Theory of the Struggle for Existence. Science 79:16-17\nChesson, P. 2000. Mechanisms of Maintenance of Species Diversity. Annual Review of Ecology and Systematics 31:343-366\nMay R.M. 1972. Will a large complex system be stable? Nature 238:413-414\nAnderson, R.M; May, R.M. 1978. Regulation and Stability of Host-Parasite Population Interactions. Journal of Animal Ecology 47:219-247\nMay R.M. & Anderson, R.M. 1979. Population biology of infectious diseases: Part II. Nature 280:455-461\nMcCann, K.S. 2000. The diversity - stability debate. Nature 405:228-233"
  },
  {
    "objectID": "ch2.html#lotka-volterra-competition",
    "href": "ch2.html#lotka-volterra-competition",
    "title": "Models for two populations",
    "section": "",
    "text": "To start our exploration of more complex models, we consider two populations (\\(X\\) and \\(Y\\)), growing logistically on their own, that interact competitively:\n\\[\n\\begin{cases}\n\\dfrac{dX}{d\\tau} = X(r_1 - B_{11} X - B_{12}Y)\\\\\n\\dfrac{dY}{d\\tau} = Y(r_2 - B_{21} X - B_{22}Y)\\\\\n\\end{cases}\n\\]\nWhere all parameters are positive; the \\(r_i\\) are the intrinsic growth rates, and \\(B_{ij}\\) measures how much the growth of \\(i\\) is decreased when adding a unit of population \\(j\\).\n\n\n\n\n\n\nMatrices and vectors\n\n\n\n\n\nA matrix \\(A\\) is a rectangular arrays of numbers (the entries of the matrix, \\(A_{ij}\\)). For this class, we will consider matrices with either real entries, \\(A_{ij} \\in \\mathbb R; A_{ij} = \\alpha\\), or complex entries, \\(A_{ij} \\in \\mathbb C; A_{ij}=\\alpha + i \\beta\\). The size of the matrix is given by the number of rows \\(n\\) and the number of columns \\(m\\). To show the size explicitly, we use \\(A_{n \\times m}\\). If \\(n = m\\) the matrix is square.\nA (column) vector \\(b\\) is a matrix with a single column (i.e., size \\(n \\times 1\\)), and a row vector \\(a^T\\) is of size \\(1 \\times m\\). We use \\({}^T\\) to denote transposition, an operation that turns the rows into columns and vice versa: \\((A^T)_{ij} = A_{ji}\\); if \\(A_{n \\times m}\\), then \\(A^{T}_{m \\times n}\\).\nBasic operations that can be performed with matrices:\n\nTwo matrices can be added only if they have the same size \\(A + B = C\\), with \\(C_{ij} = A_{ij} + B_{ij}\\).\nTwo matrices can be multiplied if the number of columns of the first matrix matches the number of rows of the second matrix: \\(A_{n \\times m} B_{m \\times l} = C_{n \\times l}\\) with \\(C_{ij} = \\sum_{k = 1}^{m} A_{ik} B_{kj}\\). In general, \\(AB \\neq BA\\): matrices do not generally commute.\nIf two matrices have the same size, we can also take the Hadamard (element-by-element) product \\(A \\circ B = C\\), with \\(C_{ij} = A_{ij} B_{ij}\\).\n\nIn R, a vector can be defined by concatenation v &lt;- c(1,2,3), and a matrix by reshaping a vector M &lt;- matrix(c(1,2,3,4), 2, 2) note that the entries are filled by column; if you want to fill them by row use M &lt;- matrix(c(1,2,3,4), 2, 2, byrow = TRUE). The Hadamard product is coded as *, and the matrix multiplication as %*%\n\n\n\nWe can gather the variables and the parameters into two vectors and a matrix:\n\\[\nZ = (X, Y)^T\\quad r = (r_1, r_2)^T\\quad B = \\begin{pmatrix}\nB_{11} & B_{12}\\\\\nB_{21} & B_{22}\n\\end{pmatrix}\n\\]\nThus, the dynamics can be written as:\n\\[\n\\dfrac{d Z_i}{d\\tau} = Z_i (r_i - \\sum_j B_{ij} Z_j)\n\\]\nor, in vector form:\n\\[\n\\dfrac{dZ}{d\\tau} = D(Z)(r - BZ)\n\\]\nNon-dimensionalization\nWe define:\n\\[\nx = c_1 X \\quad y = c_2 Y \\quad t = c_3 \\tau\n\\]\nobtaining:\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x(c_3 r_1  - c_1 c_3 B_{11} x - c_2 c_3 B_{12}y)\\\\\n\\dfrac{dy}{dt} = y(c_3 r_2 - c_1  c_3 B_{21} x - c_2 c_3 B_{22}y)\\\\\n\\end{cases}\n\\]\nA convenient choice is:\n\\[\nc_3 = \\dfrac{1}{r_1}\\quad c_1 = \\dfrac{r_1}{B_{11}}\\quad c_2 = \\dfrac{r_1}{B_{22}}\n\\]\nYielding:\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x\\left(1  - x - \\dfrac{B_{12}}{B_{22}}y \\right)\\\\\n\\dfrac{dy}{d\\tau} = y\\left(\\dfrac{r_2}{r_1} - \\dfrac{B_{21}}{B_{11}} x - y \\right)\\\\\n\\end{cases}\n\\]\nWe define the ratio of intrinsic growth rates \\(\\rho = r_2 / r_1\\) and the ratio between the effect of \\(y\\) on the growth of \\(x\\) and the effect on itself \\(A_{12} = B_{12} / B_{22}\\) and similarly \\(A_{21} = B_{21} / B_{11}\\), obtaining:\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x\\left(1  - x - A_{12 }y \\right)\\\\\n\\dfrac{dy}{d\\tau} = y\\left(\\rho - A_{21} x - y \\right)\\\\\n\\end{cases}\n\\]\nEquilibria\nThe system has a trivial equilibrium \\((x^\\star, y^\\star) = (0,0)\\), in which both species are absent. If \\(y\\) is absent, we obtain the marginal equilibrium \\((x^\\star, y^\\star) = (1,0)\\), and if \\(x\\) is absent, we have \\((x^\\star, y^\\star) = (0, \\rho)\\). Finally, we can have a coexistence equilibrium, as long as the two terms in parenthesis are simultaneously zero:\n\\[\n\\begin{cases}\n1-x^\\star-A_{12}y^\\star = 0\\\\\n\\rho - A_{21} x^\\star - y^\\star = 0\n\\end{cases}\n\\]\nSolving the first equation for \\(x^\\star\\), we obtain \\(x^\\star = 1 - A_{12} y^\\star\\); plugging this solution into the second equation yields:\n\\[\n\\begin{aligned}\n\\rho - A_{21} + A_{12}A_{21} y^\\star - y^\\star &= 0\\\\\ny^\\star &= \\dfrac{\\rho - A_{21}}{1 - A_{12}A_{21}}\n\\end{aligned}\n\\] and correspondingly:\n\\[\nx^\\star = \\dfrac{1 - A_{12} \\rho}{1 - A_{12}A_{21}}\n\\]\nIf both values of \\(x^\\star\\) and \\(y^\\star\\) are positive, we have a coexistence equilibrium, if not then the point lies outside the nonnegative orthant \\(\\mathbb R^{2}_{0+}\\), and thus cannot be reached by the dynamics.\n\n\n\n\n\n\nSolving linear systems\n\n\n\n\n\nIn the equations above, either \\(x\\) (\\(y\\)) is zero, or the term in parenthesis is zero. If we define:\n\\[\nz = (x,y)^T \\quad s = (1, \\rho)^T \\quad A = \\begin{pmatrix}\n1 & A_{12}\\\\\nA_{21} & 1\n\\end{pmatrix}\n\\]\nwe have that both terms in parenthesis are simultaneously zero whenever:\n\\[\nAz^\\star = s\n\\]\nYou can solve a system of linear equations by inverting the matrix \\(A_{n \\times n}\\). A matrix \\(A\\) is called invertible if there is a matrix \\(B\\) such that:\n\\[\nAB = BA = I_n\n\\] where \\(I_n\\) is the identity matrix, a matrix with zero everywhere but the diagonal, and with the entries on the diagonal being all 1. The identity matrix is the neutral matrix for multiplication: \\(AI = IA = A\\).\nIf such a matrix \\(B\\) exists, it is called the inverse of \\(A\\), written as \\(A^{-1}\\). If a matrix is not invertible, it is called singular. For matrices with real or complex entries, the necessary and sufficient condition for invertibility is that the determinant of the matrix \\(\\det A \\neq 0\\).\nThe determinant of a \\(2 \\times 2\\) matrix \\(A\\) can be computed as:\n\\[\nA = \\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\\quad \\det A = ad - bc\n\\]\nComputing a matrix inverse is typically quite involved. For a \\(2 \\times 2\\) matrix, you can write:\n\\[\nA^{-1} = \\dfrac{1}{ad - bc}\\begin{pmatrix}\nd & -b \\\\\n-c & a\n\\end{pmatrix}\n\\]\nFor the Lotka-Volterra system we have:\n\\[\n\\det A = 1 - A_{12} A_{21}\n\\]\nwhen the determinant is not zero, then\n\\[\n\\begin{aligned}\nA z^\\star &= s\\\\\nA^{-1} Az^\\star &= A^{-1}s\\\\\nI z^\\star &= A^{-1}s\\\\\nz^\\star &= A^{-1}s\\\\\nz^\\star &= \\dfrac{1}{1-A_{12}A_{21}}\\begin{pmatrix}\n1 & -A_{21}\\\\\n-A_{12} &1\n\\end{pmatrix} \\begin{pmatrix}\n1\\\\\n\\rho\n\\end{pmatrix}\\\\\nz^\\star &= \\dfrac{1}{1-A_{12}A_{21}}\\begin{pmatrix}\n1 - A_{21} \\rho\\\\\n\\rho - A_{12}\n\\end{pmatrix}\n\\end{aligned}\n\\]\nIn R, you can solve a system of equation using solve(A, b) where A is a square, invertible matrix, and b is a vector of appropriate size.\n\n\n\nThus, the model has three or four equilibria, depending on the parameters. Another way to see this is to think about the values of \\(y\\) making \\(dx/dt = 0\\), and viceversa.\nZero-growth isoclines\nTake the first equation, and set it to zero:\n\\[\nx\\left(1  - x - A_{12 }y \\right) = 0\n\\]\nequality is obtained when either \\(x =0\\) or \\(y = (1-x)/ A_{12}\\). This equation defines a line in the \\((x,y)\\) plane, called the phase plane. Similarly, if we take the second equation\n\\[\ny\\left(\\rho - A_{21} x - y \\right) = 0\n\\]\nwe see that this is zero whenever \\(y = 0\\) or when \\(y = \\rho - A_{21}x\\), another line in the phase plane. If the two lines meet in the positive quadrant, then we have the possibility of coexistence.\nFor example, take \\(\\rho = 1\\), \\(A_{12} = 1/3\\) and \\(A_{21} = 1/4\\):\n\n\n\n\n\nEach species grows at points that are below its zero-growth isocline, and declines at points that are above it. Thus, for each point in the phase plane we can determine the general direction of the trajectories:\n\n\n\n\n\nWe can use these arrows to classify the stability of the equilibria. For example, around \\((0,0)\\) arrows move away from the point; it is thus an unstable equilibrium. Similarly, the two marginal points have arrows pointing away from them, and are thus unstable; around the coexistence equilibrium, all arrows point back to it, indicating stability.\nIn fact, we can show trajectories converging to the coexistence equilibrium:\n\nglv2_plot_all(parms = parms_c1, \n              plot_isoclines = TRUE, \n              plot_flow = TRUE, \n              plot_trajectories = TRUE,\n              initial_conditions = matrix(c(0.01, 0.012, \n                                            1.5, 0.02,\n                                            0.1, 1.6,\n                                            1.5, 1.5), \n                                          4, 2, byrow = TRUE),\n              xlims = c(0,2), ylims = c(0,2), arrow_length = 0.15)\n\n\n\n\nDepending on the value of the parameters, we have four cases; two in which the two lines do not meet in the positive orthant; and two cases in which they do. In particular:\n\n\n\n\n\n\n\n\n\n\n\n\nEigenvalues and eigenvectors\n\n\n\n\n\nThe product of a matrix and a vector is another vector:\n\\[\nA x = b\n\\]\nEach matrix is associated with certain special vectors such that:\n\\[\nA v = \\lambda v\n\\] i.e., multiplying the vector with the matrix simply scales all the entries of the vector by a constant, \\(\\lambda\\). When this is the case, we say that \\(v\\) is an eigenvector of \\(A\\), with associated eigenvalue \\(\\lambda\\). Note that eigenvectors are defined up to a constant: if \\(v\\) is an eigenvector of \\(A\\), and \\(w = \\gamma v\\), then:\n\\[\nAw = \\gamma A v= \\gamma \\lambda v = \\lambda w\n\\]\nA matrix \\(A\\) is called diagonalizable if there exists an invertible matrix \\(P\\) such that \\(PAP^{-1} = D\\), where \\(D\\) is a diagonal matrix, i.e., having nonzero values only on the diagonal.\nExample\n\\[\nA = \\begin{pmatrix}\n1 & 2\\\\\n4 & 3\n\\end{pmatrix}\\quad v = \\begin{pmatrix}\n1\\\\\n2\n\\end{pmatrix}\\quad\nAv = \\begin{pmatrix}\n5\\\\\n10\n\\end{pmatrix} = 5 v\n\\]\nThen \\(v= (1,2)^T\\) is an eigenvector of \\(A\\) with eigenvalue \\(\\lambda = 5\\).\nA diagonalizable matrix can be written as:\n\\[\nA = Q \\Lambda Q^{-1}\n\\]\nwhere each of the columns of \\(Q\\) is an eigenvector of \\(A\\), and \\(\\Lambda\\) is a diagonal matrix with the corresponding eigenvalues. This factorization (writing a matrix as a product of other matrices) is called the eigendecomposition of \\(A\\).\nYou can see that:\n\\[\n\\begin{aligned}\nA v &= \\lambda v\\\\\nA Q &= Q \\Lambda\\\\\nA &= Q \\Lambda Q^{-1}\n\\end{aligned}\n\\]\nThe trace of a matrix is the sum of the diagonal entries, it is also the sum of the eigenvalues:\n\\[\n\\text{Tr}\\, A = \\sum_i A_{ii} = \\sum_i \\lambda_i\n\\]\nThe determinant of a matrix is the product of its eigenvalues (and thus a singular matrix has at least one zero eigenvalue):\n\\[\n\\det A = \\prod_i \\lambda_i\n\\]\nA diagonalizable matrix of size has \\(n\\) eigenvalues (not necessarily distinct) and \\(n\\) corresponding eigenvectors. The number of nonzero eigenvalues is the rank of the matrix.\nComputing the eigenvalues of a matrix is very involved, and can be done analytically only for small matrices. The eigenvalues of \\(A\\) are the zeros of the characteristic polynomial:\n\\[\n\\det (A - \\lambda I) = p(\\lambda)\n\\]\nA matrix with real entries has eigenvalues that are either real, \\(\\lambda_i = \\alpha\\), or complex \\(\\lambda = \\alpha + i \\beta\\); the complex root are paired: \\(\\lambda_{i,j} = \\alpha \\pm i \\beta\\) (conjugate complex eigenvalues). A symmetric matrix \\(A = A^T\\) has only real roots; a skew-symmetric matrix \\(A = -A^T\\) has roots with real part zero.\nThe diagonal matrix \\(D(\\alpha)\\) has eigenvalues \\(\\alpha\\).\nThe eigenvalues of the inverse \\(A^{-1}\\) are the reciprocals of the eigenvalues of \\(A\\): if \\(A\\) has eigenvalue \\(\\lambda\\), then \\(A^{-1}\\) has eigenvalue \\(1/\\lambda\\). The eigenvectors are the same. The transpose \\(A^T\\) has the same eigenvalues of \\(A\\); the eigenvectors are \\(A^T = (Q \\Lambda Q^{-1})^T = {Q^{-1}}^T \\Lambda Q^T\\)\nIf a matrix has only positive, real eigenvalues it is positive definite, if it has only nonnegative eigenvalues it is positive semi-definite; if it has only negative eigenvalues it is negative definite.\nIf \\(A\\) is positive definite, then\n\\[\n\\sum_i \\sum_j A_{ij} x_i x_j = x^T A x &gt; 0 \\quad \\forall x \\neq 0\n\\]\nIf \\(A\\) is symmetric, then it can be decomposed as:\n\\[\nA = A^T = Q \\Lambda Q^T\n\\]\ni.e., in this case \\(Q^{-1} = Q^T\\).\nFinding eigenvalues for \\(2\\times2\\) matrix\nThe matrix\n\\[\nA = \\begin{pmatrix}\na & b\\\\\nc & d\n\\end{pmatrix}\n\\]\nhas \\(\\text{Tr}\\, A = a+ d\\) and \\(\\det A = ad - bc\\). Then:\n\\[\n\\begin{cases}\n\\lambda_1 + \\lambda_2 = a + d\\\\\n\\lambda_1 \\lambda_2 = ad - bc\n\\end{cases}\n\\]\nand thus\n\\[\n\\lambda = \\dfrac{a + d \\pm \\sqrt{4bc + (a-d)^2}}{2}\n\\]\nThe eigenvectors can be found by setting one of the entries to an arbitrary value (e.g., \\(v_1 = 1\\)), and solving the equations:\n\\[\nAv = \\lambda v\n\\]\nIn R, you can compute the eigenvalues and eigenvectors of a matrix \\(A\\) as eA &lt;- eigen(A); the function returns a list with the matrix of eigenvectors stored in eA$vectors and the vector of eigenvalues in eA$values.\n\n\n\n\n\nIn the previous lectures, we have approximated the behavior of \\(f(x)\\) around the equilibrium, to determine whether small perturbations would be buffered by the system. We can perform the same type of analysis here. However, now \\(dx_i / dt = f_i(x)\\) is a function of multiple populations, and therefore we need to Taylor-expand multivariate functions.\nIn analogy with the Talyor-expansion of functions of a single variable, we can write:\n\\[\nf_i(x^\\star + \\Delta x) = f_i(x^\\star) + \\sum_k \\left. \\dfrac{\\partial f_i(x)}{\\partial x_k} \\right|_{x^\\star} \\Delta x_k + \\dfrac{1}{2} \\sum_{k}\\sum_{l} \\left. \\dfrac{\\partial^2 f_i(x)}{\\partial x_k \\partial x_l} \\right|_{x^\\star} \\Delta x_k \\Delta x_l + \\cdots\n\\] As before, \\(f_i(x^\\star) = 0\\), and if we take only the second term (i.e., the term linear in \\(\\Delta x\\)) we can approximate the function as:\n\\[\nf_i(x^\\star + \\Delta x) \\approx \\sum_k \\left. J_{ik} \\right|_{x^\\star} \\Delta x_k\n\\]\nWhere we have defined the Jacobian matrix \\(J\\):\n\\[\nJ_{ij} = \\dfrac{\\partial f_i(x)}{\\partial x_j}\n\\] For each equilibrium in the system, we can obtain a different community matrix (the name is due to Levins) \\(M\\):\n\\[\nM = \\left. J \\right|_{x^\\star}\n\\]\nAs such, a system of ODEs has a single Jacobian, and as many community matrices as there are equilibria. As before, we assume that we have slightly perturbed the system at equilibrium, \\(x(t) = x^\\star + \\Delta x\\), where \\(\\Delta x\\) is assumed to be small, and then we approximate the dynamics:\n\\[\n\\dfrac{d\\Delta x}{dt} \\approx \\left. J \\right|_{x^\\star} \\Delta x\n\\]\ni.e., we need to solve a linear system of ODEs.\n\n\n\n\n\n\nSolving systems of linear ODEs\n\n\n\n\n\nConsider the system of first-order, autnonomous ODEs:\n\\[\n\\dfrac{dx}{dt} = Ax\n\\]\nIf the matrix \\(A\\) is diagonalizable, we can decompose the matrix as:\n\\[\nA = Q \\Lambda Q^{-1}\n\\]\nWe define a new system of equations, by changing the variables:\n\\[\ny = Q^{-1}x\\quad x = Q y\n\\]\nThen, by chain rule:\n\\[\n\\dfrac{dy}{dt} = Q^{-1} \\dfrac{d x}{dt} = Q^{-1}Q \\Lambda Q^{-1} x= \\Lambda Q^{-1} x = \\Lambda y\n\\]\nWe have decoupled all equations: now the \\(y_i\\) grow or decline independently of each other.\n\\[\n\\dfrac{dy_i}{dt} = \\lambda_i y_i\n\\]\nThis is in fact the equation for the exponential growth/decay, with solution \\(y_i(t) = y(0) e^{\\lambda_i t}\\).\nWe can bring these solutions back to the original form:\n\\[\ny(t) = e^{\\Lambda t} y(0)\n\\]\nwhere \\(e^\\Lambda t\\) is a diagonal matrix:\n\\[\ne^{\\Lambda t}= \\begin{pmatrix}\ne^{\\lambda_1 t} & 0 & \\cdots &0\\\\\n0 & e^{\\lambda_2 t} & \\cdots &0\\\\\n\\cdots & \\cdots & \\cdots & \\cdots\\\\\n0 & 0 & \\cdots & e^{\\lambda_n t}\\\\\n\\end{pmatrix}\n\\]\nThen:\n\\[\nx(t) = Q y(t) = Q e^{\\Lambda t} y(0) = Q e^{\\Lambda t} Q^{-1} x(0)\n\\]\nAllowing to easily compute the solution for any linear systems of ODEs.\nStability of the origin\nSuppose that \\(\\lambda_i\\) is a real number; then \\(\\lim_{t \\to \\infty}e^{\\lambda_i t} = 0\\). If \\(\\lambda_i\\) is positive, on the other hand, then \\(\\lim_{t \\to \\infty}e^{\\lambda_i t} = \\infty\\). Thus, if any of the \\(\\lambda_i &gt; 0\\), the system will move to \\(\\infty\\) in the direction specified by the corresponding eigenvector.\nWhenever \\(\\lambda_i\\) is complex (e.g., generically, when \\(A\\) is not symmetric), then we need to consider:\n\\[\ne^{\\alpha t + i \\beta t} = e^{\\alpha t} e^{i \\beta t} = e^{\\alpha t} (\\cos \\beta + i \\sin \\beta )t\n\\]\nwhere we have used Euler’s identity. Importantly, \\((\\cos \\beta + i \\sin \\beta )\\) is bounded, and in fact its real (imaginary) part is \\(\\leq 1\\). Then, \\(\\lim_{t \\to \\infty} e^{\\alpha t + i \\beta t} = 0\\) if \\(\\alpha &lt; 0\\).\nTherefore, the vector \\(0_n\\) is an asymptotically stable equilibrium of the system \\(\\dfrac{dx}{dt} = A x\\) if and only if all the eigenvalues of \\(A\\) have negative real part.\n\n\n\nThus, to probe the local asymptotic stability of each of the equilibria, we can:\n\nCalculate the Jacobian matrix, \\(J\\)\nPlug in an equilibrium, obtaining the corresponding community matrix \\(M\\)\nCompute the eigenvalues of \\(M\\), \\(\\lambda_i\\)\nIf all the eigenvalues have negative real part, \\(\\Re (\\lambda_i) &lt; 0\\), then the equilibrium is locally asymptotically stable\n\nFor example, for the system above, we have:\n\\[\n\\begin{cases}\nf_x(x,y) = x- x^2 - A_{12}xy \\\\\nf_y(x,y) = \\rho y - A_{21} xy - y^2\n\\end{cases}\n\\]\n\\[\nJ = \\begin{pmatrix}\n(1 - 2 x - A_{12} y) & -A_{12} x\\\\\n-A_{21} y & (\\rho - 2 y - A_{21} x)\n\\end{pmatrix}\n\\] For \\((x^\\star, y^\\star) = (0,0)\\), we obtain:\n\\[\nM = \\begin{pmatrix}\n1 & 0\\\\\n0 & \\rho\n\\end{pmatrix}\n\\]\nwith eigenvalues \\(1\\) and \\(\\rho&gt;0\\): the equilibrium is unstable.\nFor the marginal equilibrium \\((x^\\star, y^\\star) = (1,0)\\), we obtain:\n\\[\nM = \\begin{pmatrix}\n-1  & -A_{12} \\\\\n0 & \\rho - A_{21}\n\\end{pmatrix}\n\\]\nThe eigenvalues are \\(-1\\) and \\(\\rho - A_{21}\\) and thus the equilibrium is stable whenever \\(\\rho &lt; A_{21}\\) and unstable when \\(\\rho &gt; A_{21}\\).\nFor the other marginal equilibrium \\((x^\\star, y^\\star) = (0,\\rho)\\), we obtain:\n\\[\nM = \\begin{pmatrix}\n1 - A_{12} \\rho & 0\\\\\n-A_{21} \\rho & -\\rho\n\\end{pmatrix}\n\\] with eigenvalues \\(-\\rho\\) and \\(1 - A_{12} \\rho\\). Thus, the equilibrium is stable whenever \\(1/\\rho &lt; A_{12}\\) and unstable when \\(1/\\rho &gt; A_{12}\\).\nFinally, whenever a feasible equilibrium \\((x^\\star, y^\\star) &gt; (0,0)\\) we have that the terms in parenthesis are zero. Thus \\((1 - x^\\star - A_{12} y^\\star) = 0\\) and \\((\\rho - y^\\star - A_{21} x^\\star)\\), yielding:\n\\[\nM = \\begin{pmatrix}\n- x^\\star & -A_{12} x^\\star\\\\\n-A_{21} y^\\star & -y^\\star\n\\end{pmatrix}\n\\]\nThe eigenvalues are:\n\\[\n\\lambda_{12} = \\dfrac{1}{2}\\left(-(x^\\star+y^\\star) \\pm \\sqrt{(x^\\star-y^\\star)^2 + 4 A_{12}A_{21} x^\\star y^\\star} \\right)\n\\]\nNote that if \\(A_{12}A_{21} = 1\\), then we have that the eigenvalues are \\(\\frac{1}{2}(-(x^\\star+y^\\star) \\pm (x^\\star+y^\\star))\\), and thus one of them is zero. Hence, the equilibrium is stable as long as \\(A_{12} A_{21} &lt; 1\\)."
  },
  {
    "objectID": "ch2.html#lotka-volterra-predator-prey-model",
    "href": "ch2.html#lotka-volterra-predator-prey-model",
    "title": "Models for two populations",
    "section": "",
    "text": "We have a prey who would grow exponentially when the predator is absent, and a predator that would decline exponentially when the prey is absent. The two species interact, thus allowing for their coexistence:\n\\[\n\\begin{cases}\n\\dfrac{dX}{d\\tau} = \\rho X - \\alpha X Y = X(\\rho - \\alpha Y)\\\\\n\\dfrac{dY}{d\\tau} = -\\delta Y + \\beta X Y = Y(-\\delta + \\beta X)\n\\end{cases}\n\\]\nwhere all parameters are positive. There are two equilibria: \\((X, Y) = (0, 0)\\) and \\((X, Y) = \\left(\\frac{\\delta}{\\beta}, \\frac{\\rho}{\\alpha} \\right)\\).\nNondimensionalization To simplify the equation (but maintain all its important features), we can define two new variables and a new time scale:\n\\[\nx = c_1 X \\quad y = c_2 Y \\quad t = c_3 \\tau\n\\]\nUsing the new variables, we write:\n\\[\n\\begin{cases}\n\\dfrac{c_1}{c_3}\\dfrac{dx}{dt} = c_1 x(\\rho - \\alpha c_2 y)\\\\\n\\dfrac{c_2}{c_3}\\dfrac{dy}{dt} = c_2 y(-\\delta + \\beta c_1 x)\n\\end{cases}\n\\] and thus\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x(c_3 \\rho - \\alpha c_2 c_3 y)\\\\\n\\dfrac{dy}{dt} = y(-c_3 \\delta + \\beta c_1 c_3 x)\n\\end{cases}\n\\]\nIt is convenient to take \\(c_3 = 1/\\rho\\), \\(c_2 = \\rho / \\alpha\\), and \\(c_1 = \\rho / \\beta\\), thus simplifying the system to:\n\\[\n\\begin{cases}\n\\dfrac{dx}{dt} = x(1 - y)\\\\\n\\dfrac{dy}{dt} = y(-\\frac{\\delta}{\\rho} + x) = y(-\\alpha + x)\n\\end{cases}\n\\]\nWe can therefore analyze the case in which we have only a single free parameter, \\(\\alpha = \\rho / \\delta &gt; 0\\). The equilibria are \\((x,y) = (0,0)\\) and \\((x, y) = (\\alpha, 1)\\).\nIsoclines of net zero growth. Clearly, the first equation is zero when either the prey is absent, or the predator is at \\(y = 1\\); the second equation is zero when either the predator is absent or the prey is at \\(x = \\alpha\\); we can draw the two lines in a plane where we have \\(x\\) on the x-axis and \\(y\\) on the y-axis. The feasible (positive) equilibrium will be at the intersection of the two lines:\n\n\n\n\n\nDirection of trajectories\nWe have four quadrants surrounding the positive equilibrium:\n\n\\(x &lt; \\alpha, y &lt; 1\\): in the bottom-left corner, we have \\(dx/dt &gt; 0\\) and \\(dy/dt &lt; 0\\); accordingly, the prey will grow and the predator decline.\n\\(x &gt; \\alpha, y &lt; 1\\): in the bottom-right corner, we have \\(dx/dt &gt; 0\\) and \\(dy/dt &gt; 0\\); accordingly, both populations will grow\n\\(x &gt; \\alpha, y &gt; 1\\): in the top-right corner, we have \\(dx/dt &lt; 0\\) and \\(dy/dt &gt; 0\\); the prey will decline, the predator grow\n\\(x &lt; \\alpha, y &gt; 1\\): in the top-left corner, we have \\(dx/dt &lt; 0\\) and \\(dy/dt &lt; 0\\); both populations will decline\n\nWe can show these directions visually, by computing \\((dx/dt, dy/dt)\\) at different values of \\((x, y)\\):"
  },
  {
    "objectID": "ch2.html#classic-papers",
    "href": "ch2.html#classic-papers",
    "title": "Models for two populations",
    "section": "",
    "text": "Vito Volterra (1926) Fluctuations in the Abundance of a Species Considered Mathematically Nature 118 : 558-60\nGause, G.F. 1934. Experimental Analysis of Vito Volterra’S Mathematical Theory of the Struggle for Existence. Science 79:16-17\nChesson, P. 2000. Mechanisms of Maintenance of Species Diversity. Annual Review of Ecology and Systematics 31:343-366\nMay R.M. 1972. Will a large complex system be stable? Nature 238:413-414\nAnderson, R.M; May, R.M. 1978. Regulation and Stability of Host-Parasite Population Interactions. Journal of Animal Ecology 47:219-247\nMay R.M. & Anderson, R.M. 1979. Population biology of infectious diseases: Part II. Nature 280:455-461\nMcCann, K.S. 2000. The diversity - stability debate. Nature 405:228-233"
  }
]